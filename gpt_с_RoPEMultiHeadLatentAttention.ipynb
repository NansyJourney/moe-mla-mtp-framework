{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f84fcbd",
      "metadata": {
        "id": "5f84fcbd"
      },
      "source": [
        "# MULTIHEAD ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9974e3de",
      "metadata": {
        "id": "9974e3de"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple, Optional, Mapping, Set, Self, NamedTuple, TypedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11f7c25d",
      "metadata": {
        "id": "11f7c25d"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c666d27f",
      "metadata": {
        "id": "c666d27f"
      },
      "source": [
        "# BUILD TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e01f273",
      "metadata": {
        "id": "7e01f273"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        eps: float = 1e-6,\n",
        "        bias: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._eps = eps\n",
        "        self._scale = nn.Parameter(torch.ones(embedding_size))\n",
        "        self._shift = nn.Parameter(torch.zeros(embedding_size)) if bias else None\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        input_dtype = x.dtype\n",
        "\n",
        "        variance = x.pow(2).mean(dim=-1, keepdim=True)\n",
        "        norm_x = x * torch.rsqrt(variance + self._eps)\n",
        "        norm_x = norm_x * self._scale\n",
        "\n",
        "        if self._shift is not None:\n",
        "            norm_x = norm_x + self._shift\n",
        "\n",
        "        return norm_x.to(input_dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64a20b6",
      "metadata": {
        "id": "e64a20b6"
      },
      "outputs": [],
      "source": [
        "class MoEFeedForward(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int, #+\n",
        "        num_experts: int, #+\n",
        "        num_experts_per_token: int, #+\n",
        "        moe_hidden_size: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._num_experts_per_tok = num_experts_per_token\n",
        "        self._num_experts = num_experts\n",
        "        self._embedding_size = embedding_size\n",
        "        self._gate = nn.Linear(embedding_size, num_experts, bias=False)\n",
        "\n",
        "        self._fc1 = nn.ModuleList(\n",
        "            [\n",
        "                nn.Linear(embedding_size, moe_hidden_size, bias=False)\n",
        "                for _ in range(num_experts)\n",
        "            ]\n",
        "        )\n",
        "        self._fc2 = nn.ModuleList(\n",
        "            [\n",
        "                nn.Linear(embedding_size, moe_hidden_size, bias=False)\n",
        "                for _ in range(num_experts)\n",
        "            ]\n",
        "        )\n",
        "        self._fc3 = nn.ModuleList(\n",
        "            [\n",
        "                nn.Linear(moe_hidden_size, embedding_size, bias=False)\n",
        "                for _ in range(num_experts)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        scores = self._gate(x)  # (b, seq_len, num_experts)\n",
        "        topk_scores, topk_indices = torch.topk(scores, self._num_experts_per_tok, dim=-1)\n",
        "        topk_probs = torch.softmax(topk_scores, dim=-1)\n",
        "\n",
        "        self.last_topk_indices = topk_indices.detach()\n",
        "\n",
        "        batch, seq_len, _ = x.shape\n",
        "        x_flat = x.reshape(batch * seq_len, -1)\n",
        "        out_flat = torch.zeros(batch * seq_len, self._embedding_size, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        topk_indices_flat = topk_indices.reshape(-1, self._num_experts_per_tok)\n",
        "        topk_probs_flat = topk_probs.reshape(-1, self._num_experts_per_tok)\n",
        "\n",
        "        unique_experts = torch.unique(topk_indices_flat)\n",
        "\n",
        "        for expert_id_tensor in unique_experts:\n",
        "            expert_id = int(expert_id_tensor.item())\n",
        "            mask = topk_indices_flat == expert_id\n",
        "            if not mask.any():\n",
        "                continue\n",
        "\n",
        "            token_mask = mask.any(dim=-1)\n",
        "            selected_idx = token_mask.nonzero(as_tuple=False).squeeze(-1)\n",
        "            if selected_idx.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            expert_input = x_flat.index_select(0, selected_idx)\n",
        "            hidden = torch.nn.functional.silu(self._fc1[expert_id](expert_input)) * self._fc2[expert_id](expert_input)\n",
        "            expert_out = self._fc3[expert_id](hidden)\n",
        "\n",
        "            mask_selected = mask[selected_idx]\n",
        "            slot_indices = mask_selected.int().argmax(dim=-1, keepdim=True)\n",
        "            selected_probs = torch.gather(topk_probs_flat.index_select(0, selected_idx), dim=-1, index=slot_indices).squeeze(-1)\n",
        "\n",
        "            out_flat.index_add_(0, selected_idx, expert_out * selected_probs.unsqueeze(-1))\n",
        "\n",
        "        return out_flat.reshape(batch, seq_len, self._embedding_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70fd64c8",
      "metadata": {
        "id": "70fd64c8"
      },
      "source": [
        "В обычном **Mixture of Experts** есть фундаментальная проблема:\n",
        "\n",
        "*   Несколько \"супер-экспертов\" становятся специалистами на всех типах данных\n",
        "*   Остальные эксперты почти никогда не активируются (\"мертвые эксперты\")\n",
        "\n",
        "Это приводит к:\n",
        "*   Неэффективному использованию параметров (платим за 16 экспертов, используем 3-4)\n",
        "*   Ухудшению обобщающей способности (меньше разнообразия в обработке)\n",
        "*   Переобучению активных экспертов\n",
        "\n",
        "В связи с этим создадим **Mixture of Experts с Noisy Top-K Gating**, чтобы избавиться от этой проблемы.\n",
        "\n",
        "Он добавляет управляемый шум в процесс выбора экспертов во время обучения, чтобы:\n",
        "\n",
        "*   \"Разведывать\" разных экспертов\n",
        "*   Балансировать нагрузку между экспертами\n",
        "*   Специализировать экспертов на разных типах данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "987ac0a8",
      "metadata": {
        "id": "987ac0a8"
      },
      "outputs": [],
      "source": [
        "class MoENoisyTopKGateFeedForward(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        num_experts: int,\n",
        "        num_experts_per_token: int,\n",
        "        moe_hidden_size: int,\n",
        "        noisy_gating: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self._num_experts_per_tok = num_experts_per_token\n",
        "        self._num_experts = num_experts\n",
        "        self._embedding_size = embedding_size\n",
        "        self.noisy_gating = noisy_gating\n",
        "        self._gate = nn.Linear(embedding_size, num_experts, bias=False)\n",
        "\n",
        "        # extra projection for Noisy Top-k Gating\n",
        "        if noisy_gating:\n",
        "            self._noise_linear = nn.Linear(embedding_size, num_experts, bias=False)\n",
        "\n",
        "        self._fc1 = nn.ModuleList([\n",
        "            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n",
        "            for _ in range(num_experts)\n",
        "        ])\n",
        "        self._fc2 = nn.ModuleList([\n",
        "            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n",
        "            for _ in range(num_experts)\n",
        "        ])\n",
        "        self._fc3 = nn.ModuleList([\n",
        "            nn.Linear(moe_hidden_size, embedding_size, bias=False)\n",
        "            for _ in range(num_experts)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        scores = self._gate(x)  # (b, seq_len, num_experts)\n",
        "\n",
        "        # ---------- 2. Add noise for Noisy Top-k ----------\n",
        "        if self.noisy_gating and self.training:\n",
        "            raw_noise_std = self._noise_linear(x)              # (B, S, E)\n",
        "            noise_std = F.softplus(raw_noise_std) + 1e-9       # H(x) = softplus(...)\n",
        "            noise = torch.randn_like(scores) * noise_std       # N(0, softplus(...))\n",
        "            scores = scores + noise                                 # noisy top-k\n",
        "\n",
        "        # ---------- 3. Top-k selection ----------\n",
        "        topk_scores, topk_indices = torch.topk(\n",
        "            scores, self._num_experts_per_tok, dim=-1\n",
        "        )\n",
        "        topk_probs = torch.softmax(topk_scores, dim=-1)\n",
        "\n",
        "        self.last_topk_indices = topk_indices.detach()\n",
        "\n",
        "        batch, seq_len, _ = x.shape\n",
        "        x_flat = x.reshape(batch * seq_len, -1)\n",
        "        out_flat = torch.zeros(batch * seq_len, self._embedding_size,\n",
        "                               device=x.device, dtype=x.dtype)\n",
        "\n",
        "        topk_indices_flat = topk_indices.reshape(-1, self._num_experts_per_tok)\n",
        "        topk_probs_flat   = topk_probs.reshape(-1, self._num_experts_per_tok)\n",
        "\n",
        "        unique_experts = torch.unique(topk_indices_flat)\n",
        "\n",
        "        for expert_id_tensor in unique_experts:\n",
        "            expert_id = int(expert_id_tensor.item())\n",
        "            mask = topk_indices_flat == expert_id\n",
        "            if not mask.any():\n",
        "                continue\n",
        "\n",
        "            token_mask = mask.any(dim=-1)\n",
        "            selected_idx = token_mask.nonzero(as_tuple=False).squeeze(-1)\n",
        "            if selected_idx.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            expert_input = x_flat.index_select(0, selected_idx)\n",
        "\n",
        "            hidden = (\n",
        "                torch.nn.functional.silu(self._fc1[expert_id](expert_input)) *\n",
        "                self._fc2[expert_id](expert_input)\n",
        "            )\n",
        "            expert_out = self._fc3[expert_id](hidden)\n",
        "\n",
        "            mask_selected = mask[selected_idx]\n",
        "            slot_indices = mask_selected.int().argmax(dim=-1, keepdim=True)\n",
        "\n",
        "            selected_probs = torch.gather(\n",
        "                topk_probs_flat.index_select(0, selected_idx),\n",
        "                dim=-1,\n",
        "                index=slot_indices\n",
        "            ).squeeze(-1)\n",
        "\n",
        "            out_flat.index_add_(\n",
        "                0,\n",
        "                selected_idx,\n",
        "                expert_out * selected_probs.unsqueeze(-1)\n",
        "            )\n",
        "\n",
        "        return out_flat.reshape(batch, seq_len, self._embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10648822",
      "metadata": {
        "id": "10648822"
      },
      "outputs": [],
      "source": [
        "class RotaryPositionEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        base: int = 1_000,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._theta = 1 / (torch.pow(torch.tensor(base), (torch.arange(0, embedding_size, 2).float() / embedding_size)))\n",
        "        self._theta = self._theta.repeat_interleave(2)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        position_ids = torch.arange(0, x.size(-2), device=x.device)\n",
        "        position_matrix = torch.outer(position_ids, self._theta.to(x.device))\n",
        "        cos = torch.cos(position_matrix)\n",
        "        sin = torch.sin(position_matrix)\n",
        "        x_odd = x[..., ::2]\n",
        "        x_even = x[..., 1::2]\n",
        "\n",
        "        _x = torch.empty_like(x, device=x.device)\n",
        "        _x[..., 0::2] = -x_even\n",
        "        _x[..., 1::2] = x_odd\n",
        "\n",
        "        _x = _x * sin[:x.size(-2), :]\n",
        "        x = x * cos[:x.size(-2), :]\n",
        "        return x + _x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a732bb63",
      "metadata": {
        "id": "a732bb63"
      },
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads: int,\n",
        "        num_kv_groups: int,\n",
        "        embedding_size: int,\n",
        "        head_embedding_size: int,\n",
        "        positional_embedding: RotaryPositionEmbedding,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._num_heads = num_heads\n",
        "        self._num_kv_groups = num_kv_groups\n",
        "        self._embedding_size = embedding_size\n",
        "        self._group_size = num_heads // num_kv_groups\n",
        "        self._head_embedding_size = head_embedding_size\n",
        "        self._positional_embedding = positional_embedding\n",
        "        self._Q = nn.Linear(self._embedding_size, self._num_heads * self._head_embedding_size)\n",
        "        self._K = nn.Linear(self._embedding_size, self._num_kv_groups * self._head_embedding_size)\n",
        "        self._V = nn.Linear(self._embedding_size, self._num_kv_groups * self._head_embedding_size)\n",
        "        self._W_proj = nn.Linear(self._num_heads * self._head_embedding_size, self._embedding_size)\n",
        "\n",
        "        self._q_norm = RMSNorm(self._head_embedding_size, eps=1e-6)\n",
        "        self._k_norm = RMSNorm(self._head_embedding_size, eps=1e-6)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: torch.Tensor,\n",
        "        key: torch.Tensor,\n",
        "        value: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        q = self._Q.forward(query).view(batch_size, -1, self._num_heads, self._head_embedding_size).transpose(1, 2)\n",
        "        k = self._K.forward(key).view(batch_size, -1, self._num_kv_groups, self._head_embedding_size).transpose(1, 2)\n",
        "        v = self._V.forward(value).view(batch_size, -1, self._num_kv_groups, self._head_embedding_size).transpose(1, 2)\n",
        "\n",
        "        q = self._q_norm.forward(q)\n",
        "        v = self._q_norm.forward(v)\n",
        "\n",
        "        q_rope = self._positional_embedding.forward(q)\n",
        "        k_rope = self._positional_embedding.forward(k)\n",
        "\n",
        "        k_rope = k_rope.repeat_interleave(self._group_size, dim=1)\n",
        "        v = v.repeat_interleave(self._group_size, dim=1)\n",
        "\n",
        "        a = torch.matmul(q_rope, k_rope.transpose(-1, -2)) / torch.sqrt(torch.tensor(self._head_embedding_size))\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            a = a.masked_fill(mask == 0, -torch.inf)\n",
        "\n",
        "        alpha = F.softmax(a, -1)\n",
        "\n",
        "        z = torch.matmul(alpha, v).transpose(1, 2).contiguous().view(batch_size, -1, self._num_heads * self._head_embedding_size)\n",
        "        return self._W_proj(z)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mSXy3DcHi58_",
      "metadata": {
        "id": "mSXy3DcHi58_"
      },
      "source": [
        "Теперь вместо механизма **GroupedQueryAttention** мы создадим класс **RoPEMultiHeadLatentAttention**. Это позволит использовать латентный attention вместе с поворотными позиционными эмбеддингами (RoPE), что уменьшает вычислительную нагрузку, снижает объём KV-кэша и улучшает работу модели на длинных последовательностях"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oz_z3THvjZlw",
      "metadata": {
        "id": "oz_z3THvjZlw"
      },
      "source": [
        "Сперва покажем пример для **MultiHeadLatentAttention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "OkrKxx3gi5lK",
      "metadata": {
        "id": "OkrKxx3gi5lK"
      },
      "outputs": [],
      "source": [
        "class MultiHeadLatentAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads: int,\n",
        "        embedding_size: int,\n",
        "        head_embedding_size: int,\n",
        "        dropout: float,\n",
        "        qkv_bias: bool = False,\n",
        "        latent_dim: Optional[int] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_embedding_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.d_out = num_heads * head_embedding_size\n",
        "\n",
        "        # Latent-space dimensionality\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else max(16, self.d_out // 8)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # Unified naming with classical MHA:\n",
        "        #   W_Q : Query projection\n",
        "        #   W_C : Down-projection → latent \"C\"\n",
        "        #   W_K : Up-projection latent → Keys\n",
        "        #   W_V : Up-projection latent → Values\n",
        "        #   W_O : Output projection\n",
        "        # ---------------------------------------------------------\n",
        "\n",
        "        self.W_Q = nn.Linear(embedding_size, self.d_out, bias=qkv_bias)\n",
        "        self.W_C = nn.Linear(embedding_size, self.latent_dim, bias=qkv_bias)\n",
        "\n",
        "        self.W_K = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n",
        "        self.W_V = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n",
        "\n",
        "        self.W_O = nn.Linear(self.d_out, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Latent KV-cache\n",
        "        self.register_buffer(\"cache_c_kv\", None, persistent=False)\n",
        "        self.ptr = 0\n",
        "\n",
        "    def reset_cache(self):\n",
        "        self.cache_c_kv = None\n",
        "        self.ptr = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def reshape_heads(x, num_heads, head_dim):\n",
        "        # (b, T, num_heads * head_dim) → (b, num_heads, T, head_dim)\n",
        "        b, T, _ = x.shape\n",
        "        return x.view(b, T, num_heads, head_dim).transpose(1, 2).contiguous()\n",
        "\n",
        "    def forward(self, x, use_cache: bool = False):\n",
        "        \"\"\"\n",
        "        x: (batch, T, embedding_size)\n",
        "        \"\"\"\n",
        "        b, T, _ = x.shape\n",
        "        h = self.num_heads\n",
        "        d = self.head_dim\n",
        "\n",
        "        Q_all = self.W_Q(x)\n",
        "        C_new = self.W_C(x)\n",
        "\n",
        "        if use_cache:\n",
        "            if self.cache_c_kv is None:\n",
        "                C_total = C_new\n",
        "            else:\n",
        "                C_total = torch.cat([self.cache_c_kv, C_new], dim=1)\n",
        "\n",
        "            self.cache_c_kv = C_total\n",
        "        else:\n",
        "            C_total = C_new\n",
        "\n",
        "        K_all = self.W_K(C_total)\n",
        "        V_all = self.W_V(C_total)\n",
        "\n",
        "        Q = self.reshape_heads(Q_all, h, d)\n",
        "        K = self.reshape_heads(K_all, h, d)\n",
        "        V = self.reshape_heads(V_all, h, d)\n",
        "\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
        "\n",
        "        T_Q = Q.shape[-2]\n",
        "        T_K = K.shape[-2]\n",
        "\n",
        "        device = Q.device\n",
        "\n",
        "        if use_cache:\n",
        "            q_pos = torch.arange(self.ptr, self.ptr + T_Q, device=device, dtype=torch.long)\n",
        "            self.ptr += T_Q\n",
        "        else:\n",
        "            q_pos = torch.arange(T_Q, device=device, dtype=torch.long)\n",
        "            self.ptr = 0\n",
        "\n",
        "        k_pos = torch.arange(T_K, device=device, dtype=torch.long)\n",
        "\n",
        "        causal_mask = q_pos.unsqueeze(-1) < k_pos.unsqueeze(0)\n",
        "        attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (K.shape[-1]**0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = (attn_weights @ V)\n",
        "        context = context.transpose(1, 2).contiguous()\\\n",
        "                           .view(b, T, self.d_out)\n",
        "\n",
        "        out = self.W_O(context)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "TmCFuHUxjoLo",
      "metadata": {
        "id": "TmCFuHUxjoLo"
      },
      "outputs": [],
      "source": [
        "class RoPEMultiHeadLatentAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads: int,\n",
        "        embedding_size: int,\n",
        "        head_embedding_size: int,\n",
        "        dropout: float,\n",
        "        positional_embedding: RotaryPositionEmbedding,\n",
        "        qkv_bias: bool = False,\n",
        "        latent_dim: Optional[int] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_embedding_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.d_out = num_heads * head_embedding_size\n",
        "\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else max(16, self.d_out // 8)\n",
        "\n",
        "        self.W_Q = nn.Linear(embedding_size, self.d_out, bias=qkv_bias)\n",
        "        self.W_C = nn.Linear(embedding_size, self.latent_dim, bias=qkv_bias)\n",
        "\n",
        "        self.W_K = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n",
        "        self.W_V = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n",
        "\n",
        "        self.W_O = nn.Linear(self.d_out, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rope = positional_embedding\n",
        "\n",
        "        # Latent cache\n",
        "        self.register_buffer(\"cache_c_kv\", None, persistent=False)\n",
        "        self.ptr = 0\n",
        "\n",
        "    def reset_cache(self):\n",
        "        self.cache_c_kv = None\n",
        "        self.ptr = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def reshape_heads(x, num_heads, head_dim):\n",
        "        b, T, _ = x.shape\n",
        "        return x.view(b, T, num_heads, head_dim).transpose(1, 2).contiguous()\n",
        "\n",
        "    def forward(self, x, use_cache=False):\n",
        "        \"\"\"\n",
        "        x: (b, T, embedding_size)\n",
        "        \"\"\"\n",
        "        b, T, _ = x.shape\n",
        "        h = self.num_heads\n",
        "        d = self.head_dim\n",
        "\n",
        "        Q_all = self.W_Q(x)\n",
        "        C_new = self.W_C(x)\n",
        "\n",
        "        if use_cache:\n",
        "            if self.cache_c_kv is None:\n",
        "                C_total = C_new\n",
        "            else:\n",
        "                C_total = torch.cat([self.cache_c_kv, C_new], dim=1)\n",
        "            self.cache_c_kv = C_total.detach()\n",
        "        else:\n",
        "            C_total = C_new\n",
        "\n",
        "        K_all = self.W_K(C_total)\n",
        "        V_all = self.W_V(C_total)\n",
        "\n",
        "        Q = self.reshape_heads(Q_all, h, d)\n",
        "        K = self.reshape_heads(K_all, h, d)\n",
        "        V = self.reshape_heads(V_all, h, d)\n",
        "\n",
        "        Q = self.rope(Q)\n",
        "        K = self.rope(K)\n",
        "\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1))\n",
        "\n",
        "        T_Q = Q.shape[-2]\n",
        "        T_K = K.shape[-2]\n",
        "        device = x.device\n",
        "\n",
        "        if use_cache:\n",
        "            q_pos = torch.arange(self.ptr, self.ptr + T_Q, device=device)\n",
        "            self.ptr += T_Q\n",
        "        else:\n",
        "            q_pos = torch.arange(T_Q, device=device)\n",
        "            self.ptr = 0\n",
        "\n",
        "        k_pos = torch.arange(T_K, device=device)\n",
        "\n",
        "        causal_mask = q_pos.unsqueeze(-1) < k_pos.unsqueeze(0)\n",
        "        attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / (d ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = attn_weights @ V\n",
        "        context = context.transpose(1, 2).contiguous().view(b, T, self.d_out)\n",
        "\n",
        "        return self.W_O(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "e1b8cfc1",
      "metadata": {
        "id": "e1b8cfc1"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        num_heads: int,\n",
        "        num_kv_groups: int,\n",
        "        num_experts: int,\n",
        "        num_experts_per_token: int,\n",
        "        head_embedding_size: int,\n",
        "        fcnn_hidden_size: int,\n",
        "        positional_embedding: RotaryPositionEmbedding,\n",
        "        dropout: float = 0.1,\n",
        "        use_mla: bool = False,\n",
        "        use_noisy_moe: bool = False,\n",
        "        noisy_gating: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # --- Attention ---\n",
        "        if use_mla:\n",
        "            self._mla = RoPEMultiHeadLatentAttention(\n",
        "            embedding_size=embedding_size,\n",
        "            num_heads=num_heads,\n",
        "            head_embedding_size=head_embedding_size,\n",
        "            dropout=dropout,\n",
        "            positional_embedding=positional_embedding\n",
        "            )\n",
        "        else:\n",
        "          self._gqa = GroupedQueryAttention(\n",
        "              embedding_size=embedding_size,\n",
        "              num_heads=num_heads,\n",
        "              num_kv_groups=num_kv_groups,\n",
        "              head_embedding_size=head_embedding_size,\n",
        "              positional_embedding=positional_embedding,\n",
        "          )\n",
        "\n",
        "        # --- MoE: обычный или noisy ---\n",
        "        if use_noisy_moe:\n",
        "            self._fcnn = MoENoisyTopKGateFeedForward(\n",
        "                embedding_size=embedding_size,\n",
        "                num_experts=num_experts,\n",
        "                num_experts_per_token=num_experts_per_token,\n",
        "                moe_hidden_size=fcnn_hidden_size,\n",
        "                noisy_gating=noisy_gating,\n",
        "            )\n",
        "        else:\n",
        "            self._fcnn = MoEFeedForward(\n",
        "                embedding_size=embedding_size,\n",
        "                num_experts=num_experts,\n",
        "                num_experts_per_token=num_experts_per_token,\n",
        "                moe_hidden_size=fcnn_hidden_size,\n",
        "            )\n",
        "\n",
        "        self._rms_norm1 = RMSNorm(embedding_size)\n",
        "        self._rms_norm2 = RMSNorm(embedding_size)\n",
        "        self._dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        use_cache: bool = False\n",
        "    ) -> torch.Tensor:\n",
        "        z = self._rms_norm1(x)\n",
        "        if hasattr(self, \"_gqa\"):\n",
        "          z = self._gqa(x, x, x, mask)\n",
        "        else:\n",
        "          z = self._mla(x, use_cache=use_cache)\n",
        "\n",
        "        x = x + self._dropout(z)\n",
        "\n",
        "        z = self._rms_norm2(x)\n",
        "        z = self._fcnn(z)\n",
        "        return x + self._dropout(z)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        n_layers: int,\n",
        "        embedding_size: int,\n",
        "        num_heads: int,\n",
        "        num_kv_groups: int,\n",
        "        num_experts: int,\n",
        "        num_experts_per_token: int,\n",
        "        head_embedding_size: int,\n",
        "        fcnn_hidden_size: int,\n",
        "        dropout: float = 0.1,\n",
        "        use_mla: bool = False,\n",
        "        use_noisy_moe: bool = False,\n",
        "        noisy_gating: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self._embeddings = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_size,\n",
        "            padding_idx=0,\n",
        "        )\n",
        "\n",
        "        self._positional_embedding = RotaryPositionEmbedding(\n",
        "            embedding_size=head_embedding_size,\n",
        "        )\n",
        "\n",
        "        self._layers = nn.ModuleList([\n",
        "            DecoderLayer(\n",
        "                embedding_size=embedding_size,\n",
        "                num_heads=num_heads,\n",
        "                num_kv_groups=num_kv_groups,\n",
        "                num_experts=num_experts,\n",
        "                num_experts_per_token=num_experts_per_token,\n",
        "                head_embedding_size=head_embedding_size,\n",
        "                fcnn_hidden_size=fcnn_hidden_size,\n",
        "                positional_embedding=self._positional_embedding,\n",
        "                dropout=dropout,\n",
        "                use_mla=use_mla,\n",
        "                use_noisy_moe=use_noisy_moe,\n",
        "                noisy_gating=noisy_gating,\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        self._rms_norm = RMSNorm(embedding_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.LongTensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        use_cache: bool = False\n",
        "    ) -> torch.Tensor:\n",
        "        z = self._embeddings(x)\n",
        "        for layer in self._layers:\n",
        "            z = layer(z, mask, use_cache)\n",
        "        return self._rms_norm(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "46946fb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46946fb8",
        "outputId": "4a0e76b2-87ba-4b4c-e082-2d62874a2db3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 5, 64])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.LongTensor(\n",
        "    [\n",
        "        [0, 1, 2, 0, 0],\n",
        "        [0, 1, 2, 0, 0],\n",
        "        [0, 1, 2, 0, 0],\n",
        "        [0, 1, 2, 0, 0],\n",
        "    ]\n",
        ")\n",
        "decoder = Decoder(\n",
        "    vocab_size=50,\n",
        "    n_layers=3,\n",
        "    embedding_size=64,\n",
        "    num_heads=8,\n",
        "    num_kv_groups=2,\n",
        "    num_experts=16,\n",
        "    num_experts_per_token=8,\n",
        "    head_embedding_size=32,\n",
        "    fcnn_hidden_size=128,\n",
        "    dropout = 0,\n",
        "    use_mla=True\n",
        ")\n",
        "decoder._embeddings(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "679b1694",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "679b1694",
        "outputId": "d7dbbea1-b56e-40e0-acd1-e107014ce96e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.0959,  1.6796,  0.3880,  ..., -2.0898, -0.2728, -2.0297],\n",
              "         [-1.6025,  1.6556,  0.4725,  ..., -1.4524, -1.0326, -0.1407],\n",
              "         [-1.4382,  0.1749, -0.1794,  ..., -1.2244, -0.9672, -1.3663],\n",
              "         [-0.1845,  0.0659,  1.4954,  ..., -1.2112, -0.0659,  0.0316],\n",
              "         [-0.2875,  0.2585,  1.3719,  ..., -1.1639, -0.0954, -0.0699]],\n",
              "\n",
              "        [[-1.0959,  1.6796,  0.3880,  ..., -2.0898, -0.2728, -2.0297],\n",
              "         [-1.6025,  1.6556,  0.4725,  ..., -1.4524, -1.0326, -0.1407],\n",
              "         [-1.4382,  0.1749, -0.1794,  ..., -1.2244, -0.9672, -1.3663],\n",
              "         [-0.1845,  0.0659,  1.4954,  ..., -1.2112, -0.0659,  0.0316],\n",
              "         [-0.2875,  0.2585,  1.3719,  ..., -1.1639, -0.0954, -0.0699]],\n",
              "\n",
              "        [[-1.0959,  1.6796,  0.3880,  ..., -2.0898, -0.2728, -2.0297],\n",
              "         [-1.6025,  1.6556,  0.4725,  ..., -1.4524, -1.0326, -0.1407],\n",
              "         [-1.4382,  0.1749, -0.1794,  ..., -1.2244, -0.9672, -1.3663],\n",
              "         [-0.1845,  0.0659,  1.4954,  ..., -1.2112, -0.0659,  0.0316],\n",
              "         [-0.2875,  0.2585,  1.3719,  ..., -1.1639, -0.0954, -0.0699]],\n",
              "\n",
              "        [[-1.0959,  1.6796,  0.3880,  ..., -2.0898, -0.2728, -2.0297],\n",
              "         [-1.6025,  1.6556,  0.4725,  ..., -1.4524, -1.0326, -0.1407],\n",
              "         [-1.4382,  0.1749, -0.1794,  ..., -1.2244, -0.9672, -1.3663],\n",
              "         [-0.1845,  0.0659,  1.4954,  ..., -1.2112, -0.0659,  0.0316],\n",
              "         [-0.2875,  0.2585,  1.3719,  ..., -1.1639, -0.0954, -0.0699]]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "f3e3d46a",
      "metadata": {
        "id": "f3e3d46a"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        n_layers: int,\n",
        "        embedding_size: int,\n",
        "        num_heads: int,\n",
        "        num_kv_groups: int,\n",
        "        num_experts: int,\n",
        "        num_experts_per_token: int,\n",
        "        head_embedding_size: int,\n",
        "        fcnn_hidden_size: int,\n",
        "        dropout: float = 0.1,\n",
        "        use_mla: bool = False,\n",
        "        use_noisy_moe: bool = False,\n",
        "        noisy_gating: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self._decoder = Decoder(\n",
        "            vocab_size=vocab_size,\n",
        "            n_layers=n_layers,\n",
        "            embedding_size=embedding_size,\n",
        "            num_heads=num_heads,\n",
        "            num_kv_groups=num_kv_groups,\n",
        "            num_experts=num_experts,\n",
        "            num_experts_per_token=num_experts_per_token,\n",
        "            head_embedding_size=head_embedding_size,\n",
        "            fcnn_hidden_size=fcnn_hidden_size,\n",
        "            dropout=dropout,\n",
        "            use_mla=use_mla,\n",
        "            use_noisy_moe=use_noisy_moe,\n",
        "            noisy_gating=noisy_gating,\n",
        "        )\n",
        "\n",
        "        self._logits = nn.Linear(embedding_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.LongTensor,\n",
        "        use_cache: bool = False\n",
        "    ) -> torch.Tensor:\n",
        "        mask = ~torch.triu(torch.ones((1, x.size(-1), x.size(-1)), device=x.device), 1).to(torch.bool)\n",
        "        mask = mask & (x != 0).unsqueeze(1)\n",
        "        z = self._decoder(x, mask, use_cache)\n",
        "        return self._logits(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "b3186b98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3186b98",
        "outputId": "3fbfff54-aeb9-4860-ebc2-7085c2290ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 5, 50])\n",
            "torch.Size([4, 5, 50])\n"
          ]
        }
      ],
      "source": [
        "x = torch.LongTensor(\n",
        "    [\n",
        "        [3, 1, 2, 0, 0],\n",
        "        [4, 1, 2, 0, 0],\n",
        "        [3, 1, 2, 0, 0],\n",
        "        [2, 1, 2, 4, 6],\n",
        "    ]\n",
        ")\n",
        "transformer_mha = Transformer(\n",
        "    vocab_size=50,\n",
        "    n_layers=3,\n",
        "    embedding_size=64,\n",
        "    num_heads=8,\n",
        "    num_kv_groups=2,\n",
        "    num_experts=16,\n",
        "    num_experts_per_token=8,\n",
        "    head_embedding_size=32,\n",
        "    fcnn_hidden_size=128,\n",
        "    use_mla=False\n",
        ")\n",
        "\n",
        "transformer_mla  = Transformer(\n",
        "    vocab_size=50,\n",
        "    n_layers=3,\n",
        "    embedding_size=64,\n",
        "    num_heads=8,\n",
        "    num_kv_groups=2,\n",
        "    num_experts=16,\n",
        "    num_experts_per_token=8,\n",
        "    head_embedding_size=32,\n",
        "    fcnn_hidden_size=128,\n",
        "    use_mla=True\n",
        ")\n",
        "\n",
        "print(transformer_mha(x).shape)\n",
        "print(transformer_mla(x).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9557664",
      "metadata": {
        "id": "d9557664"
      },
      "source": [
        "# TRAIN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZgtQWcYtsB9n",
      "metadata": {
        "id": "ZgtQWcYtsB9n"
      },
      "source": [
        "#### Символьная языковая модель (character-level LM), которая обучена на корпусе имён и фамилий.\n",
        "\n",
        "**Вход**: начальный текст, например \"Красотка\" (может быть имя или часть фамилии).\n",
        "\n",
        "**Задача**: продолжить текст, сгенерировать следующие символы фамилии или имени, пока не встретится символ конца </s> или не будет достигнута максимальная длина."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "7d2944cb",
      "metadata": {
        "id": "7d2944cb"
      },
      "outputs": [],
      "source": [
        "class CharTokenizer:\n",
        "    def __init__(self):\n",
        "        self._start_token = \"<s>\"\n",
        "        self._end_token = \"</s>\"\n",
        "        self._unknown_token = \"<UNK>\"\n",
        "        self._padding_token = \"<PAD>\"\n",
        "        self._cls_token = \"<CLS>\"\n",
        "        self._sep_token = \"<SEP>\"\n",
        "        self._padding_id = 0\n",
        "        self._cls_id = 1\n",
        "        self._sep_id = 2\n",
        "        self._start_token_id = 3\n",
        "        self._end_token_id = 4\n",
        "        self._unknown_token_id = 5\n",
        "        self._init_vocab()\n",
        "\n",
        "    @property\n",
        "    def vocab(self) -> Mapping[int, str]:\n",
        "        return self._vocab\n",
        "\n",
        "    @property\n",
        "    def reverse_vocab(self) -> Mapping[int, str]:\n",
        "        return {token: id for id, token in self._vocab.items()}\n",
        "\n",
        "    @property\n",
        "    def start_token_id(self) -> int:\n",
        "        return self._start_token_id\n",
        "\n",
        "    @property\n",
        "    def end_token_id(self) -> int:\n",
        "        return self._end_token_id\n",
        "\n",
        "    def _init_vocab(self) -> None:\n",
        "        self._vocab = {\n",
        "            self._padding_id: self._padding_token,\n",
        "            self._cls_id: self._cls_token,\n",
        "            self._sep_id: self._sep_token,\n",
        "            self._start_token_id: self._start_token,\n",
        "            self._end_token_id: self._end_token,\n",
        "            self._unknown_token_id: self._unknown_token,\n",
        "        }\n",
        "\n",
        "    def fit(self, corpus: List[str]) -> Self:\n",
        "        self._init_vocab()\n",
        "        flat_corpus = \"\\n\".join(corpus)\n",
        "        for char in set(flat_corpus):\n",
        "            if char in self._vocab.values():\n",
        "                continue\n",
        "            self._vocab[len(self._vocab)] = char\n",
        "        return self\n",
        "\n",
        "    def tokenize_text(self, text: str | List[str]) -> List[str] | List[List[str]]:\n",
        "        if isinstance(text, str):\n",
        "            return self._tokenize_text(text)\n",
        "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
        "        return [self._tokenize_text(chunk) for chunk in text]\n",
        "\n",
        "    def tokenize_ids(self, text: str | List[str]) -> List[int] | List[List[int]]:\n",
        "        if isinstance(text, str):\n",
        "            return self._tokenize_ids(text)\n",
        "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
        "        return [self._tokenize_ids(chunk) for chunk in text]\n",
        "\n",
        "    def decode(self, tokens: List[int]) -> str:\n",
        "        content = []\n",
        "        for token in tokens:\n",
        "            if token in [self._padding_id, self._cls_id, self._sep_id, self._start_token_id, self._end_token_id, self._unknown_token_id]:\n",
        "                continue\n",
        "            content.append(\n",
        "                self._vocab.get(token, self._unknown_token)\n",
        "            )\n",
        "        return \"\".join(content)\n",
        "\n",
        "    def _tokenize_text(self, text: str) -> List[str]:\n",
        "        tokens = [self._start_token]\n",
        "        reverse_vocab = self.reverse_vocab\n",
        "        for char in list(text):\n",
        "            if char in reverse_vocab:\n",
        "               tokens.append(char)\n",
        "            else:\n",
        "                tokens.append(self._unknown_token)\n",
        "        tokens.append(self._end_token)\n",
        "        return tokens\n",
        "\n",
        "    def _tokenize_ids(self, text: str) -> List[int]:\n",
        "        tokens = self._tokenize_text(text)\n",
        "        reversed_vocab = self.reverse_vocab\n",
        "        tokens_ids = [reversed_vocab[token] for token in tokens]\n",
        "        return tokens_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "23d63ab4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d63ab4",
        "outputId": "14fb83c1-5621-41ae-a326-c2ee5b89f8d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Вениамин Садеретдинов',\n",
              " 'Софья Шумуртова',\n",
              " 'Павел Скаков',\n",
              " 'Емельян Рабеев',\n",
              " 'Василиса Анциева',\n",
              " 'Игнатий Ридзевский',\n",
              " 'Вероника Котонова',\n",
              " 'Алеся Шиманцова',\n",
              " 'Фаина Шаготова',\n",
              " 'Марат Прядохин']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names = pl.read_parquet(\"names.parquet\")\n",
        "surnames = pl.read_parquet(\"surnames.parquet\")\n",
        "\n",
        "def get_persons(names: pl.DataFrame, surnames: pl.DataFrame, n: int = 100) -> List[str]:\n",
        "    persons = []\n",
        "    for _ in range(n):\n",
        "        sex = np.random.choice([\"m\", \"f\"]).item()\n",
        "        name = names.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n",
        "        surname = surnames.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n",
        "        persons.append(f\"{name} {surname}\")\n",
        "    return persons\n",
        "\n",
        "corpus = get_persons(names, surnames, 10_000)\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6bc28635",
      "metadata": {
        "id": "6bc28635"
      },
      "outputs": [],
      "source": [
        "tokenizer = CharTokenizer().fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "9262c9c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9262c9c0",
        "outputId": "c0ccbdca-0ee7-4f79-ec11-d58ee78ce7f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '<PAD>',\n",
              " 1: '<CLS>',\n",
              " 2: '<SEP>',\n",
              " 3: '<s>',\n",
              " 4: '</s>',\n",
              " 5: '<UNK>',\n",
              " 6: 'ы',\n",
              " 7: 'к',\n",
              " 8: 'Я',\n",
              " 9: 'З',\n",
              " 10: 'д',\n",
              " 11: 'C',\n",
              " 12: 'I',\n",
              " 13: 'М',\n",
              " 14: 'о',\n",
              " 15: 'А',\n",
              " 16: ',',\n",
              " 17: 'я',\n",
              " 18: 'О',\n",
              " 19: '\\n',\n",
              " 20: 'а',\n",
              " 21: 'ь',\n",
              " 22: ' ',\n",
              " 23: 'в',\n",
              " 24: 'И',\n",
              " 25: 'ч',\n",
              " 26: 'ж',\n",
              " 27: 'ш',\n",
              " 28: 'h',\n",
              " 29: 'ё',\n",
              " 30: 'с',\n",
              " 31: 'Ц',\n",
              " 32: 'н',\n",
              " 33: 'Ш',\n",
              " 34: 'С',\n",
              " 35: 'з',\n",
              " 36: 'ф',\n",
              " 37: 'Н',\n",
              " 38: 'Э',\n",
              " 39: 'К',\n",
              " 40: 'p',\n",
              " 41: 'р',\n",
              " 42: 'Ч',\n",
              " 43: 'Р',\n",
              " 44: 'л',\n",
              " 45: 'х',\n",
              " 46: 'Щ',\n",
              " 47: 'б',\n",
              " 48: 'Х',\n",
              " 49: 'ц',\n",
              " 50: 'Ф',\n",
              " 51: 'м',\n",
              " 52: 'Л',\n",
              " 53: 'й',\n",
              " 54: 'ю',\n",
              " 55: 'Г',\n",
              " 56: 'Б',\n",
              " 57: 'П',\n",
              " 58: 'щ',\n",
              " 59: 'ъ',\n",
              " 60: 'Ж',\n",
              " 61: '-',\n",
              " 62: 'т',\n",
              " 63: 'Т',\n",
              " 64: 'Ю',\n",
              " 65: 'Е',\n",
              " 66: 'Д',\n",
              " 67: 'е',\n",
              " 68: 'г',\n",
              " 69: 'э',\n",
              " 70: '.',\n",
              " 71: 'В',\n",
              " 72: 'п',\n",
              " 73: 'У',\n",
              " 74: 'у',\n",
              " 75: 'и'}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f8883ab5",
      "metadata": {
        "id": "f8883ab5"
      },
      "outputs": [],
      "source": [
        "class SimpleTextDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        corpus: List[str],\n",
        "        fitted_tokenizer: CharTokenizer,\n",
        "        max_seq_length: int = 100,\n",
        "    ):\n",
        "        self._data: List[List[int]] = []\n",
        "\n",
        "        for sentence in corpus:\n",
        "            x = fitted_tokenizer.tokenize_ids(sentence[:max_seq_length - 2])\n",
        "            self._data.append(x)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[List[int], List[int]]:\n",
        "        return torch.LongTensor(self._data[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b740a5df",
      "metadata": {
        "id": "b740a5df"
      },
      "outputs": [],
      "source": [
        "def collate(data: List[torch.Tensor]):\n",
        "    x = [torch.LongTensor(seq) for seq in data]\n",
        "    return nn.utils.rnn.pad_sequence(x, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "083643c1",
      "metadata": {
        "id": "083643c1"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "BATCH_SIZE = 256\n",
        "MAX_SEQ_LEN = 200\n",
        "N_LAYERS = 6\n",
        "EMBEDDING_SIZE = 64\n",
        "NUM_HEADS = 8\n",
        "NUM_KV_GROUPS = 2\n",
        "NUM_EXPERTS = 16\n",
        "NUM_EXPERTS_PER_TOKEN = 2\n",
        "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
        "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
        "n_epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "5b689383",
      "metadata": {
        "id": "5b689383"
      },
      "outputs": [],
      "source": [
        "dataset = SimpleTextDataset(\n",
        "    corpus=corpus,\n",
        "    fitted_tokenizer=tokenizer,\n",
        "    max_seq_length=MAX_SEQ_LEN,\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "38d11b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d11b09",
        "outputId": "e5a2471c-0910-4d2f-8398-3c0eb418c58b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([256, 28])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(dataloader)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fm-7D97xtRBW",
      "metadata": {
        "id": "fm-7D97xtRBW"
      },
      "source": [
        "С целью верификации преимуществ **MLA** выполнено сравнительное обучение двух архитектур: базовой MoE и её модификации с шумовым механизмом выбора экспертов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "2313eee5",
      "metadata": {
        "id": "2313eee5"
      },
      "outputs": [],
      "source": [
        "model_mha = Transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_kv_groups=NUM_KV_GROUPS,\n",
        "    num_experts=NUM_EXPERTS,\n",
        "    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n",
        "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
        "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
        "    dropout=0.15,\n",
        "    use_mla=False,\n",
        "    use_noisy_moe=True,\n",
        "    noisy_gating=True\n",
        ")\n",
        "\n",
        "model_mla = Transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_kv_groups=NUM_KV_GROUPS,\n",
        "    num_experts=NUM_EXPERTS,\n",
        "    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n",
        "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
        "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
        "    dropout=0.15,\n",
        "    use_mla=True,\n",
        "    use_noisy_moe=True,\n",
        "    noisy_gating=True\n",
        ")\n",
        "optimizer_mha = Adam(model_mha.parameters(), lr=4e-3)\n",
        "optimizer_mla = Adam(model_mla.parameters(), lr=4e-3)\n",
        "loss_func = nn.CrossEntropyLoss(reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "4a5f7551",
      "metadata": {
        "id": "4a5f7551"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def compute_perplexity(model, dataloader, loss_func, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x in dataloader:\n",
        "            curr_x = x[:, :-1].to(device)\n",
        "            next_x = x[:, 1:].clone().to(device)\n",
        "            next_x[(curr_x == 0) | (curr_x == 4)] = 0\n",
        "\n",
        "            logits = model(curr_x, use_cache=False)\n",
        "            token_losses = loss_func(logits.transpose(1, 2), next_x.long())\n",
        "            loss = token_losses.sum()\n",
        "            nonpad = (token_losses > 0).sum()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_tokens += nonpad.item()\n",
        "\n",
        "    mean_loss = total_loss / total_tokens\n",
        "    return math.exp(mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "lvErRI6Byzxy",
      "metadata": {
        "id": "lvErRI6Byzxy"
      },
      "outputs": [],
      "source": [
        "def train_and_collect(model, n_epoch, dataloader, loss_func, optimizer, num_experts, device):\n",
        "    epoch_loss = []\n",
        "    expert_usage_list = []\n",
        "    ppl_list = []\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        model.train()\n",
        "        losses = []\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "\n",
        "        # Для агрегации по всем слоям\n",
        "        all_layers_topk_indices = []\n",
        "\n",
        "        for x in tqdm(dataloader):\n",
        "            curr_x = x[:, :-1]\n",
        "            next_x = x[:, 1:].clone()\n",
        "            next_x[(curr_x == 0) | (curr_x == 4)] = 0\n",
        "\n",
        "            curr_x = curr_x.to(device)\n",
        "            next_x = next_x.to(device)\n",
        "\n",
        "            logits = model(curr_x, use_cache=False)\n",
        "\n",
        "            batch_indices = []\n",
        "            for decoder_layer in model._decoder._layers:\n",
        "                if hasattr(decoder_layer._fcnn, 'last_topk_indices') and decoder_layer._fcnn.last_topk_indices is not None:\n",
        "                    batch_indices.append(decoder_layer._fcnn.last_topk_indices.detach())\n",
        "\n",
        "            if batch_indices:\n",
        "                combined_batch = torch.cat(batch_indices, dim=0)\n",
        "                all_layers_topk_indices.append(combined_batch)\n",
        "            else:\n",
        "                print(\"No topk indices found\")\n",
        "\n",
        "            token_losses = loss_func(logits.transpose(1, 2), next_x.long())\n",
        "            loss = token_losses.sum() / (token_losses > 0).sum()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss.append(np.mean(losses))\n",
        "\n",
        "        if all_layers_topk_indices:\n",
        "            all_topk_flat = torch.cat([t.reshape(-1) for t in all_layers_topk_indices])\n",
        "            usage = np.array([(all_topk_flat.cpu().numpy() == i).sum() for i in range(num_experts)])\n",
        "        else:\n",
        "            usage = np.zeros(num_experts, dtype=int)\n",
        "\n",
        "        expert_usage_list.append(usage)\n",
        "\n",
        "        ppl = compute_perplexity(model, dataloader, loss_func, device)\n",
        "        ppl_list.append(ppl)\n",
        "\n",
        "        print(f\"Loss: {epoch_loss[-1]:.4f} | PPL: {ppl:.4f} | usage: {usage.tolist()}\")\n",
        "\n",
        "    return epoch_loss, expert_usage_list, ppl_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "7a275895",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7a275895",
        "outputId": "ded15f47-9033-4224-cf33-29b616570d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7902 | PPL: 3.5199 | usage: [153666, 167151, 116460, 213951, 246818, 175084, 218593, 208319, 170041, 324472, 197827, 202704, 213999, 125899, 172897, 211543]\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.1280 | PPL: 2.6241 | usage: [145561, 229840, 90500, 275050, 224867, 181086, 200210, 166997, 181259, 344947, 182685, 174025, 238857, 118807, 217338, 165443]\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9694 | PPL: 2.4609 | usage: [148021, 260215, 82214, 285000, 239077, 192932, 168426, 155229, 161900, 373896, 170627, 179765, 224599, 110753, 216053, 169149]\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9345 | PPL: 2.4348 | usage: [140915, 258552, 83377, 298321, 237654, 186614, 142373, 151227, 141797, 378123, 183912, 185422, 221575, 100035, 219206, 181105]\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9074 | PPL: 2.4118 | usage: [147699, 249944, 74519, 313342, 223384, 194146, 139651, 141341, 142210, 378828, 193679, 194872, 228404, 92937, 230576, 192132]\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9041 | PPL: 2.3542 | usage: [151817, 242866, 74543, 318750, 217757, 198275, 136269, 141642, 136758, 380267, 179692, 186304, 232803, 101303, 228465, 194601]\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8981 | PPL: 2.3380 | usage: [147652, 232803, 78054, 329984, 212270, 191635, 136433, 140553, 129226, 399619, 174934, 184031, 206192, 105053, 239249, 199256]\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8938 | PPL: 2.3402 | usage: [150030, 228756, 79296, 304397, 210859, 200265, 134038, 145384, 133958, 389631, 178905, 192567, 197233, 99977, 235383, 223001]\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8862 | PPL: 2.3001 | usage: [141362, 244208, 79033, 313491, 222887, 194524, 128549, 141010, 139681, 393354, 184070, 178179, 211172, 91101, 239186, 207825]\n",
            "Epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8689 | PPL: 2.2984 | usage: [143304, 241853, 79345, 298557, 216004, 191074, 132827, 153135, 146680, 402561, 189334, 185567, 209555, 95245, 226714, 240885]\n",
            "Epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8702 | PPL: 2.2834 | usage: [150126, 242328, 87706, 309225, 201617, 182441, 131591, 145540, 139705, 417738, 175549, 188844, 199380, 97477, 219064, 236661]\n",
            "Epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8641 | PPL: 2.2569 | usage: [139588, 231220, 91583, 312755, 201817, 187972, 128364, 149050, 146172, 395662, 179508, 193110, 200422, 85075, 238623, 235431]\n",
            "Epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8517 | PPL: 2.2483 | usage: [138032, 238876, 95637, 310142, 208491, 190495, 129876, 148515, 147785, 392479, 188271, 189676, 192032, 89436, 239786, 231991]\n",
            "Epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8533 | PPL: 2.2446 | usage: [139825, 229953, 92267, 289611, 201158, 191931, 137232, 156447, 151356, 399365, 183185, 188182, 198212, 91703, 232035, 245986]\n",
            "Epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8501 | PPL: 2.2185 | usage: [126759, 230309, 100537, 302708, 204685, 192688, 131042, 161537, 142625, 383403, 182242, 186081, 200832, 96297, 221931, 258820]\n",
            "Epoch 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8462 | PPL: 2.2221 | usage: [132400, 232869, 88892, 294561, 214037, 187097, 138451, 158837, 142876, 386945, 195114, 182009, 196910, 102839, 213375, 248564]\n",
            "Epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8333 | PPL: 2.1788 | usage: [126879, 239583, 77565, 295062, 206652, 186488, 132006, 149091, 156517, 400592, 200290, 192361, 208533, 101873, 219836, 244144]\n",
            "Epoch 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8272 | PPL: 2.1893 | usage: [130392, 221734, 75400, 289422, 202577, 188649, 143594, 161668, 153938, 411139, 197747, 205664, 195947, 89400, 223015, 235666]\n",
            "Epoch 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8293 | PPL: 2.1652 | usage: [127084, 225497, 82952, 277719, 196598, 185140, 141224, 160833, 165387, 393195, 198921, 188256, 202176, 103046, 211567, 241205]\n",
            "Epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8283 | PPL: 2.1317 | usage: [124551, 218214, 84638, 267941, 188289, 184441, 145877, 161521, 161195, 405308, 201808, 195106, 202769, 101175, 226961, 233886]\n",
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:05<00:00,  6.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7371 | PPL: 3.5469 | usage: [137221, 237564, 134219, 139321, 144050, 219295, 300072, 117295, 164126, 258842, 258769, 188346, 234843, 186314, 160511, 223276]\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.2034 | PPL: 2.6834 | usage: [118473, 264100, 89756, 101552, 156435, 175311, 345745, 109131, 182682, 246871, 274543, 178089, 278210, 213395, 161504, 204619]\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.0241 | PPL: 2.4716 | usage: [114178, 282585, 94358, 94769, 158559, 140604, 342909, 108249, 201364, 220698, 296307, 186648, 268793, 219903, 160010, 235826]\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9743 | PPL: 2.4754 | usage: [114747, 277093, 77278, 95400, 143428, 120007, 343107, 96896, 206694, 239775, 268618, 224863, 269153, 219809, 156956, 237376]\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9478 | PPL: 2.4177 | usage: [115542, 279123, 80837, 75122, 129027, 146609, 353760, 104720, 200296, 225322, 277688, 223108, 298343, 221122, 156532, 244369]\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9314 | PPL: 2.3969 | usage: [120673, 278790, 82640, 70600, 124204, 152093, 328490, 81850, 199210, 248843, 268682, 221890, 300334, 253166, 165097, 222862]\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9356 | PPL: 2.3719 | usage: [116312, 259191, 92754, 74417, 125862, 156490, 358397, 84778, 196955, 259841, 287937, 208103, 275426, 222305, 175441, 212543]\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9028 | PPL: 2.3747 | usage: [136618, 255642, 80899, 76880, 135923, 162305, 355583, 97147, 195960, 255823, 291693, 225020, 268614, 206547, 183510, 231004]\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8958 | PPL: 2.3989 | usage: [130774, 262045, 92136, 80244, 130186, 158760, 336086, 105644, 195559, 263095, 258076, 230926, 268168, 214586, 183622, 246189]\n",
            "Epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:05<00:00,  6.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9012 | PPL: 2.3612 | usage: [122948, 259483, 78221, 75842, 133232, 158372, 335742, 110020, 197576, 273211, 255016, 220111, 284488, 203294, 181771, 238929]\n",
            "Epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9128 | PPL: 2.3294 | usage: [111696, 265205, 70110, 72047, 134749, 156818, 290000, 110108, 203222, 255236, 249198, 229447, 313762, 203582, 185303, 240909]\n",
            "Epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.9078 | PPL: 2.3214 | usage: [121277, 261162, 68306, 62713, 139194, 164966, 281183, 111178, 201973, 253550, 245205, 235511, 324674, 213823, 170822, 260239]\n",
            "Epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8999 | PPL: 2.3395 | usage: [136483, 261515, 86712, 63742, 123998, 161775, 288222, 114185, 206879, 251819, 229563, 219023, 319426, 213234, 167769, 262599]\n",
            "Epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8853 | PPL: 2.3299 | usage: [141299, 276546, 81812, 63902, 125049, 151545, 309350, 114580, 206425, 247721, 212759, 213794, 307457, 238378, 181739, 277596]\n",
            "Epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8958 | PPL: 2.3186 | usage: [118956, 281087, 81999, 65489, 121770, 149353, 301165, 118883, 201718, 248183, 221849, 203871, 309667, 215723, 181870, 294001]\n",
            "Epoch 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8846 | PPL: 2.3009 | usage: [116419, 294105, 78026, 67440, 110006, 139099, 308799, 112665, 208789, 235784, 236527, 196569, 317029, 222995, 195937, 294403]\n",
            "Epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8751 | PPL: 2.2894 | usage: [108415, 319589, 89575, 72877, 112075, 140479, 307976, 110129, 206323, 228288, 231586, 188807, 323231, 223183, 193228, 294191]\n",
            "Epoch 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8841 | PPL: 2.3229 | usage: [115493, 314555, 88325, 72184, 120041, 141160, 300872, 97229, 201717, 230202, 225730, 195632, 304766, 219919, 192480, 298735]\n",
            "Epoch 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8793 | PPL: 2.2931 | usage: [117941, 339956, 93242, 77064, 118360, 137797, 302325, 79664, 213150, 233228, 222073, 211089, 309681, 207903, 190925, 267906]\n",
            "Epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.8808 | PPL: 2.3072 | usage: [117899, 298411, 99892, 76088, 121129, 75653, 323607, 88560, 261865, 220807, 160987, 222257, 301247, 320520, 192984, 240590]\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\"\n",
        "model_mha.to(device)\n",
        "model_mla.to(device)\n",
        "\n",
        "loss_mha, usage_mha, ppl_mha = train_and_collect(\n",
        "    model_mha, n_epoch, dataloader, loss_func, optimizer_mha, NUM_EXPERTS, device\n",
        ")\n",
        "\n",
        "loss_mla, usage_mla, ppl_mla = train_and_collect(\n",
        "    model_mla, n_epoch, dataloader, loss_func, optimizer_mla, NUM_EXPERTS, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "_9vDkaImiBDG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "_9vDkaImiBDG",
        "outputId": "5299f1dd-acce-4608-e250-863380946001"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(loss_mha)+1)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(8,5))\n",
        "\n",
        "# ===== Loss =====\n",
        "ax1.plot(epochs, loss_mha, 'b-o', label='Loss MHA')\n",
        "ax1.plot(epochs, loss_mla, 'b--o', label='Loss MLA')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "# ===== PPL =====\n",
        "ax2 = ax1.twinx()  # создаем вторую ось Y\n",
        "ax2.plot(epochs, ppl_mha, 'r-o', label='PPL MHA')\n",
        "ax2.plot(epochs, ppl_mla, 'r--o', label='PPL MLA')\n",
        "ax2.set_ylabel('Perplexity', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "# ===== легенда =====\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n",
        "\n",
        "plt.title(\"Loss & Perplexity Comparison\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "f8821cf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8821cf7",
        "outputId": "f32588e5-f46a-4662-94ac-977504f2e6b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float32 (PyTorch default): 36.6929 MB\n",
            "bfloat16: 18.3464 MB\n"
          ]
        }
      ],
      "source": [
        "def model_memory_size(model, input_dtype=torch.float32):\n",
        "    total_params = 0\n",
        "    total_grads = 0\n",
        "    for param in model.parameters():\n",
        "        # Calculate total number of elements per parameter\n",
        "        param_size = param.numel()\n",
        "        total_params += param_size\n",
        "        # Check if gradients are stored for this parameter\n",
        "        if param.requires_grad:\n",
        "            total_grads += param_size\n",
        "\n",
        "    # Calculate buffer size (non-parameters that require memory)\n",
        "    total_buffers = sum(buf.numel() for buf in model.buffers())\n",
        "\n",
        "    # Size in bytes = (Number of elements) * (Size of each element in bytes)\n",
        "    # We assume parameters and gradients are stored in the same type as input dtype\n",
        "    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n",
        "    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n",
        "\n",
        "    # Convert bytes to megabytes\n",
        "    total_memory_mb = total_memory_bytes / (1024**2)\n",
        "\n",
        "    return total_memory_mb\n",
        "\n",
        "print(f\"float32 (PyTorch default): {model_memory_size(model_mla, input_dtype=torch.float32):.4f} MB\")\n",
        "print(f\"bfloat16: {model_memory_size(model_mla, input_dtype=torch.bfloat16):.4f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059c0d5b",
      "metadata": {
        "id": "059c0d5b"
      },
      "source": [
        "# TEST MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "bcbd24fb",
      "metadata": {
        "id": "bcbd24fb"
      },
      "outputs": [],
      "source": [
        "def generate(\n",
        "    model: nn.Module,\n",
        "    text_input: str,\n",
        "    tokenizer: CharTokenizer,\n",
        "    max_steps: int = 100,\n",
        "    device: str = \"cuda\",\n",
        ") -> str:\n",
        "    model = model.to(device)\n",
        "    x = tokenizer.tokenize_ids(text_input)[:-1]\n",
        "    x_cpu = torch.tensor(x, dtype=torch.int32).unsqueeze(0)\n",
        "    x_device = x_cpu.to(device)\n",
        "    generated_tokens = []\n",
        "    for _ in range(max_steps):\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_device)\n",
        "            probs = F.softmax(logits[0][-1], dim=-1)\n",
        "            next_x = torch.multinomial(probs, 1).item()\n",
        "\n",
        "        if next_x == 4:\n",
        "            break\n",
        "        gen = torch.tensor([next_x], dtype=torch.int32).unsqueeze(0).to(device)\n",
        "        x_device = torch.concat((x_device, gen), dim=-1)\n",
        "        generated_tokens.append(next_x)\n",
        "    return tokenizer.decode(x + generated_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "e8016cab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8016cab",
        "outputId": "5dfa75c6-47ff-49dd-ee2d-e9ac48afb8c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (_decoder): Decoder(\n",
              "    (_embeddings): Embedding(76, 64, padding_idx=0)\n",
              "    (_positional_embedding): RotaryPositionEmbedding()\n",
              "    (_layers): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (_mla): RoPEMultiHeadLatentAttention(\n",
              "          (W_Q): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (W_C): Linear(in_features=64, out_features=16, bias=False)\n",
              "          (W_K): Linear(in_features=16, out_features=64, bias=False)\n",
              "          (W_V): Linear(in_features=16, out_features=64, bias=False)\n",
              "          (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (dropout): Dropout(p=0.15, inplace=False)\n",
              "          (rope): RotaryPositionEmbedding()\n",
              "        )\n",
              "        (_fcnn): MoENoisyTopKGateFeedForward(\n",
              "          (_gate): Linear(in_features=64, out_features=16, bias=False)\n",
              "          (_noise_linear): Linear(in_features=64, out_features=16, bias=False)\n",
              "          (_fc1): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n",
              "          )\n",
              "          (_fc2): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n",
              "          )\n",
              "          (_fc3): ModuleList(\n",
              "            (0-15): 16 x Linear(in_features=256, out_features=64, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (_rms_norm1): RMSNorm()\n",
              "        (_rms_norm2): RMSNorm()\n",
              "        (_dropout): Dropout(p=0.15, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (_rms_norm): RMSNorm()\n",
              "  )\n",
              "  (_logits): Linear(in_features=64, out_features=76, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_mla.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "f4a4c3f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f4a4c3f8",
        "outputId": "b3c045fc-bcc0-4312-c6f2-6f61e20e0b0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Гений Сельмутдин'"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(\n",
        "    model=model_mla,\n",
        "    text_input=\"Гений\",\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "f9zeOkCr9LmZ",
      "metadata": {
        "id": "f9zeOkCr9LmZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
