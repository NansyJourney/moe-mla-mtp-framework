{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14154906,"sourceType":"datasetVersion","datasetId":9021889}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5f84fcbd","cell_type":"markdown","source":"# MULTIHEAD ATTENTION","metadata":{"id":"5f84fcbd"}},{"id":"9974e3de","cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n\nimport re\nfrom typing import List, Dict, Any, Tuple, Optional, Mapping, Set, Self, NamedTuple, TypedDict","metadata":{"id":"9974e3de","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:47:40.134855Z","iopub.execute_input":"2025-12-14T18:47:40.135020Z","iopub.status.idle":"2025-12-14T18:47:44.567538Z","shell.execute_reply.started":"2025-12-14T18:47:40.135003Z","shell.execute_reply":"2025-12-14T18:47:44.566846Z"}},"outputs":[],"execution_count":1},{"id":"11f7c25d","cell_type":"code","source":"def fix_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)","metadata":{"id":"11f7c25d","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:47:50.259614Z","iopub.execute_input":"2025-12-14T18:47:50.260129Z","iopub.status.idle":"2025-12-14T18:47:50.264036Z","shell.execute_reply.started":"2025-12-14T18:47:50.260105Z","shell.execute_reply":"2025-12-14T18:47:50.263192Z"}},"outputs":[],"execution_count":2},{"id":"c666d27f","cell_type":"markdown","source":"# BUILD TRANSFORMER","metadata":{"id":"c666d27f"}},{"id":"7e01f273","cell_type":"code","source":"class RMSNorm(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        eps: float = 1e-6,\n        bias: bool = False,\n    ) -> None:\n        super().__init__()\n        self._eps = eps\n        self._scale = nn.Parameter(torch.ones(embedding_size))\n        self._shift = nn.Parameter(torch.zeros(embedding_size)) if bias else None\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        input_dtype = x.dtype\n\n        variance = x.pow(2).mean(dim=-1, keepdim=True)\n        norm_x = x * torch.rsqrt(variance + self._eps)\n        norm_x = norm_x * self._scale\n\n        if self._shift is not None:\n            norm_x = norm_x + self._shift\n\n        return norm_x.to(input_dtype)","metadata":{"id":"7e01f273","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:47:52.633530Z","iopub.execute_input":"2025-12-14T18:47:52.634371Z","iopub.status.idle":"2025-12-14T18:47:52.639896Z","shell.execute_reply.started":"2025-12-14T18:47:52.634341Z","shell.execute_reply":"2025-12-14T18:47:52.639208Z"}},"outputs":[],"execution_count":3},{"id":"987ac0a8","cell_type":"code","source":"class MoENoisyTopKGateFeedForward(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        moe_hidden_size: int,\n        noisy_gating: bool = True,\n    ) -> None:\n        super().__init__()\n\n        self._num_experts_per_tok = num_experts_per_token\n        self._num_experts = num_experts\n        self._embedding_size = embedding_size\n        self.noisy_gating = noisy_gating\n        self._gate = nn.Linear(embedding_size, num_experts, bias=False)\n\n        # extra projection for Noisy Top-k Gating\n        if noisy_gating:\n            self._noise_linear = nn.Linear(embedding_size, num_experts, bias=False)\n\n        self._fc1 = nn.ModuleList([\n            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n            for _ in range(num_experts)\n        ])\n        self._fc2 = nn.ModuleList([\n            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n            for _ in range(num_experts)\n        ])\n        self._fc3 = nn.ModuleList([\n            nn.Linear(moe_hidden_size, embedding_size, bias=False)\n            for _ in range(num_experts)\n        ])\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        scores = self._gate(x)  # (b, seq_len, num_experts)\n\n        # ---------- 2. Add noise for Noisy Top-k ----------\n        if self.noisy_gating and self.training:\n            raw_noise_std = self._noise_linear(x)              # (B, S, E)\n            noise_std = F.softplus(raw_noise_std) + 1e-9       # H(x) = softplus(...)\n            noise = torch.randn_like(scores) * noise_std       # N(0, softplus(...))\n            scores = scores + noise                                 # noisy top-k\n\n        # ---------- 3. Top-k selection ----------\n        topk_scores, topk_indices = torch.topk(\n            scores, self._num_experts_per_tok, dim=-1\n        )\n        topk_probs = torch.softmax(topk_scores, dim=-1)\n\n        self.last_topk_indices = topk_indices.detach()\n\n        batch, seq_len, _ = x.shape\n        x_flat = x.reshape(batch * seq_len, -1)\n        out_flat = torch.zeros(batch * seq_len, self._embedding_size,\n                               device=x.device, dtype=x.dtype)\n\n        topk_indices_flat = topk_indices.reshape(-1, self._num_experts_per_tok)\n        topk_probs_flat   = topk_probs.reshape(-1, self._num_experts_per_tok)\n\n        unique_experts = torch.unique(topk_indices_flat)\n\n        for expert_id_tensor in unique_experts:\n            expert_id = int(expert_id_tensor.item())\n            mask = topk_indices_flat == expert_id\n            if not mask.any():\n                continue\n\n            token_mask = mask.any(dim=-1)\n            selected_idx = token_mask.nonzero(as_tuple=False).squeeze(-1)\n            if selected_idx.numel() == 0:\n                continue\n\n            expert_input = x_flat.index_select(0, selected_idx)\n\n            hidden = (\n                torch.nn.functional.silu(self._fc1[expert_id](expert_input)) *\n                self._fc2[expert_id](expert_input)\n            )\n            expert_out = self._fc3[expert_id](hidden)\n\n            mask_selected = mask[selected_idx]\n            slot_indices = mask_selected.int().argmax(dim=-1, keepdim=True)\n\n            selected_probs = torch.gather(\n                topk_probs_flat.index_select(0, selected_idx),\n                dim=-1,\n                index=slot_indices\n            ).squeeze(-1)\n\n            out_flat.index_add_(\n                0,\n                selected_idx,\n                expert_out * selected_probs.unsqueeze(-1)\n            )\n\n        return out_flat.reshape(batch, seq_len, self._embedding_size)","metadata":{"id":"987ac0a8","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:47:55.282781Z","iopub.execute_input":"2025-12-14T18:47:55.283360Z","iopub.status.idle":"2025-12-14T18:47:55.294262Z","shell.execute_reply.started":"2025-12-14T18:47:55.283335Z","shell.execute_reply":"2025-12-14T18:47:55.293544Z"}},"outputs":[],"execution_count":4},{"id":"5bbfa7a0-3898-4e65-bdd4-af4c568604c1","cell_type":"code","source":"class MultiHeadLatentAttention(nn.Module):\n    def __init__(\n        self,\n        num_heads: int,\n        embedding_size: int,\n        head_embedding_size: int,\n        dropout: float,\n        qkv_bias: bool = False,\n        latent_dim: Optional[int] = None,\n    ):\n        super().__init__()\n\n        self.num_heads = num_heads\n        self.head_dim = head_embedding_size\n        self.embedding_size = embedding_size\n        self.d_out = num_heads * head_embedding_size\n\n        # Latent-space dimensionality\n        self.latent_dim = latent_dim if latent_dim is not None else max(16, self.d_out // 8)\n\n        # ---------------------------------------------------------\n        # Unified naming with classical MHA:\n        #   W_Q : Query projection\n        #   W_C : Down-projection → latent \"C\"\n        #   W_K : Up-projection latent → Keys\n        #   W_V : Up-projection latent → Values\n        #   W_O : Output projection\n        # ---------------------------------------------------------\n\n        self.W_Q = nn.Linear(embedding_size, self.d_out, bias=qkv_bias)\n        self.W_C = nn.Linear(embedding_size, self.latent_dim, bias=qkv_bias)\n\n        self.W_K = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n        self.W_V = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n\n        self.W_O = nn.Linear(self.d_out, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n\n        # Latent KV-cache\n        self.register_buffer(\"cache_c_kv\", None, persistent=False)\n        self.ptr = 0\n\n    def reset_cache(self):\n        self.cache_c_kv = None\n        self.ptr = 0\n\n    @staticmethod\n    def reshape_heads(x, num_heads, head_dim):\n        # (b, T, num_heads * head_dim) → (b, num_heads, T, head_dim)\n        b, T, _ = x.shape\n        return x.view(b, T, num_heads, head_dim).transpose(1, 2).contiguous()\n\n    def forward(self, x, attention_mask=None, use_cache: bool = False):\n        \"\"\"\n        x: (batch, T, embedding_size)\n        \"\"\"\n        b, T, _ = x.shape\n        h = self.num_heads\n        d = self.head_dim\n\n        Q_all = self.W_Q(x)\n        C_new = self.W_C(x)\n\n        if use_cache:\n            if self.cache_c_kv is None:\n                C_total = C_new\n            else:\n                C_total = torch.cat([self.cache_c_kv, C_new], dim=1)\n\n            self.cache_c_kv = C_total\n        else:\n            C_total = C_new\n\n        K_all = self.W_K(C_total)\n        V_all = self.W_V(C_total)\n\n        Q = self.reshape_heads(Q_all, h, d)\n        K = self.reshape_heads(K_all, h, d)\n        V = self.reshape_heads(V_all, h, d)\n\n        attn_scores = torch.matmul(Q, K.transpose(-2, -1))\n\n        T_Q = Q.shape[-2]\n        T_K = K.shape[-2]\n\n        device = Q.device\n\n        if use_cache:\n            q_pos = torch.arange(self.ptr, self.ptr + T_Q, device=device, dtype=torch.long)\n            self.ptr += T_Q\n        else:\n            q_pos = torch.arange(T_Q, device=device, dtype=torch.long)\n            self.ptr = 0\n\n        k_pos = torch.arange(T_K, device=device, dtype=torch.long)\n\n        causal_mask = q_pos.unsqueeze(-1) < k_pos.unsqueeze(0)\n        attn_scores.masked_fill_(causal_mask, -torch.inf)\n\n        attn_weights = torch.softmax(attn_scores / (K.shape[-1]**0.5), dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        context = (attn_weights @ V)\n        context = context.transpose(1, 2).contiguous()\\\n                           .view(b, T, self.d_out)\n\n        out = self.W_O(context)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:48:05.661982Z","iopub.execute_input":"2025-12-14T18:48:05.662679Z","iopub.status.idle":"2025-12-14T18:48:05.675087Z","shell.execute_reply.started":"2025-12-14T18:48:05.662652Z","shell.execute_reply":"2025-12-14T18:48:05.674270Z"}},"outputs":[],"execution_count":5},{"id":"p6eNamhIJWsp","cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        num_heads: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        head_embedding_size: int,\n        fcnn_hidden_size: int,\n        dropout: float = 0.1,\n    ) -> None:\n        super().__init__()\n\n        self._mla = MultiHeadLatentAttention(\n            embedding_size=embedding_size,\n            num_heads=num_heads,\n            head_embedding_size=head_embedding_size,\n            dropout=dropout\n        )\n\n        self._fcnn = MoENoisyTopKGateFeedForward(\n            embedding_size=embedding_size,\n            num_experts=num_experts,\n            num_experts_per_token=num_experts_per_token,\n            moe_hidden_size=fcnn_hidden_size,\n            noisy_gating=True\n        )\n\n        self._rms_norm1 = RMSNorm(embedding_size)\n        self._rms_norm2 = RMSNorm(embedding_size)\n        self._dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, attention_mask=None, use_cache: bool = False):\n        z = self._rms_norm1(x)\n        z = self._mla(z, attention_mask=attention_mask, use_cache=use_cache)\n        x = x + self._dropout(z)\n\n        z = self._rms_norm2(x)\n        z = self._fcnn(z)\n        return x + self._dropout(z)","metadata":{"id":"p6eNamhIJWsp","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:48:11.936896Z","iopub.execute_input":"2025-12-14T18:48:11.937493Z","iopub.status.idle":"2025-12-14T18:48:11.943381Z","shell.execute_reply.started":"2025-12-14T18:48:11.937468Z","shell.execute_reply":"2025-12-14T18:48:11.942637Z"}},"outputs":[],"execution_count":6},{"id":"4f698b83-3b72-4cd3-9350-e1b59da03315","cell_type":"markdown","source":"Реализуем класс **MTPTransformer**, предназначенный для обучения модели на задаче предсказания следующих трёх токенов последовательности. Алгоритм реализован на основе методологии MTP (Multi-Token Prediction), предложенной в архитектуре DeepSeek.","metadata":{}},{"id":"uZPwLpubxYIb","cell_type":"code","source":"class MTPTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_size: int,\n        n_layers: int,\n        embedding_size: int,\n        num_heads: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        head_embedding_size: int,\n        fcnn_hidden_size: int,\n        dropout: float = 0.1,\n        mtp_k: int = 3,\n        max_seq_len: int = 2048,\n    ) -> None:\n        super().__init__()\n\n        self.vocab_size = vocab_size\n        self.mtp_k = mtp_k\n        self.n_layers = n_layers\n        self.embedding_size = embedding_size\n        self.max_seq_len = max_seq_len\n\n        self._embeddings = nn.Embedding(\n            num_embeddings=vocab_size,\n            embedding_dim=embedding_size,\n            padding_idx=0,\n        )\n\n        self.main_layers = nn.ModuleList([\n            DecoderLayer(\n                embedding_size=embedding_size,\n                num_heads=num_heads,\n                num_experts=num_experts,\n                num_experts_per_token=num_experts_per_token,\n                head_embedding_size=head_embedding_size,\n                fcnn_hidden_size=fcnn_hidden_size,\n                dropout=dropout\n            )\n            for _ in range(n_layers)\n        ])\n\n        self.mtp_layers = nn.ModuleList([\n            DecoderLayer(\n                embedding_size=embedding_size,\n                num_heads=num_heads,\n                num_experts=num_experts,\n                num_experts_per_token=num_experts_per_token,\n                head_embedding_size=head_embedding_size,\n                fcnn_hidden_size=fcnn_hidden_size,\n                dropout=dropout\n            )\n            for _ in range(mtp_k - 1)\n        ])\n\n        self._rms_norm = RMSNorm(embedding_size)\n        self.projections = nn.ModuleList([\n            nn.Linear(2 * embedding_size, embedding_size)\n            for _ in range(mtp_k - 1)\n        ])\n\n        self._logits = nn.Linear(embedding_size, vocab_size, bias=False)\n        self._logits.weight = self._embeddings.weight\n\n    def forward(self, x: torch.LongTensor, attention_mask=None, use_cache: bool = False):\n        B, T = x.shape\n\n        # Валидация входа\n        if T < self.mtp_k:\n            raise ValueError(f\"Sequence length {T} must be >= mtp_k={self.mtp_k}\")\n\n        max_seq_len = T - self.mtp_k\n\n        # Эмбеддинги\n        z = self._embeddings(x)\n\n        # Основной путь\n        h_main = z[:, :max_seq_len, :]\n        for layer in self.main_layers:\n            h_main = layer(h_main, attention_mask=attention_mask, use_cache=use_cache)\n\n        logits_main = self._logits(h_main)\n        outputs = [logits_main]\n        h_prev = h_main\n\n        # MTP этапы\n        for k in range(1, self.mtp_k):\n            start_idx = k\n            end_idx = max_seq_len + k\n\n            # Корректная индексация для MTP токенов\n            h_curr_emb = z[:, start_idx:end_idx, :]\n\n            # Нормализация и проекция\n            h_norm = self._rms_norm(h_prev)\n            e_norm = self._rms_norm(h_curr_emb)\n            merged = torch.cat([h_norm, e_norm], dim=-1)\n            h_prime = self.projections[k-1](merged)\n\n            # MTP слой\n            h_k = self.mtp_layers[k-1](h_prime, attention_mask=attention_mask, use_cache=use_cache)\n\n            logits_k = self._logits(h_k)\n            outputs.append(logits_k)\n            h_prev = h_k\n\n        # Стек logits: [B, seq_len, mtp_k, vocab_size]\n        return torch.stack(outputs, dim=2)","metadata":{"id":"uZPwLpubxYIb","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:17.621249Z","iopub.execute_input":"2025-12-14T18:51:17.621766Z","iopub.status.idle":"2025-12-14T18:51:17.632217Z","shell.execute_reply.started":"2025-12-14T18:51:17.621739Z","shell.execute_reply":"2025-12-14T18:51:17.631513Z"}},"outputs":[],"execution_count":10},{"id":"b3186b98","cell_type":"code","source":"x = torch.LongTensor(\n    [\n        [3, 1, 2, 0, 0],\n        [4, 1, 2, 0, 0],\n        [3, 1, 2, 0, 0],\n        [2, 1, 2, 4, 6],\n    ]\n)\n\ntransformer_mtp = MTPTransformer(\n    vocab_size=50,\n    n_layers=3,\n    embedding_size=64,\n    num_heads=8,\n    num_experts=16,\n    num_experts_per_token=8,\n    head_embedding_size=32,\n    fcnn_hidden_size=128,\n    dropout = 0.1,\n    mtp_k = 2\n)\n\nattention_mask = (x != 0).float()\n\noutput = transformer_mtp(x, attention_mask=attention_mask)\nprint(output.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3186b98","outputId":"892e4c0c-589a-4b96-a7c0-3120d1f1aca1","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:21.236088Z","iopub.execute_input":"2025-12-14T18:51:21.236359Z","iopub.status.idle":"2025-12-14T18:51:21.313391Z","shell.execute_reply.started":"2025-12-14T18:51:21.236336Z","shell.execute_reply":"2025-12-14T18:51:21.312658Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 2, 50])\n","output_type":"stream"}],"execution_count":11},{"id":"d9557664","cell_type":"markdown","source":"# TRAIN MODEL","metadata":{"id":"d9557664"}},{"id":"ZgtQWcYtsB9n","cell_type":"markdown","source":"#### Символьная языковая модель (character-level LM), которая обучена на корпусе имён и фамилий.\n\n**Вход**: начальный текст, например \"Красотка\" (может быть имя или часть фамилии).\n\n**Задача**: продолжить текст, сгенерировать следующие символы фамилии или имени, пока не встретится символ конца </s> или не будет достигнута максимальная длина.","metadata":{"id":"ZgtQWcYtsB9n"}},{"id":"7d2944cb","cell_type":"code","source":"class CharTokenizer:\n    def __init__(self):\n        self._start_token = \"<s>\"\n        self._end_token = \"</s>\"\n        self._unknown_token = \"<UNK>\"\n        self._padding_token = \"<PAD>\"\n        self._cls_token = \"<CLS>\"\n        self._sep_token = \"<SEP>\"\n        self._padding_id = 0\n        self._cls_id = 1\n        self._sep_id = 2\n        self._start_token_id = 3\n        self._end_token_id = 4\n        self._unknown_token_id = 5\n        self._init_vocab()\n\n    @property\n    def vocab(self) -> Mapping[int, str]:\n        return self._vocab\n\n    @property\n    def reverse_vocab(self) -> Mapping[int, str]:\n        return {token: id for id, token in self._vocab.items()}\n\n    @property\n    def start_token_id(self) -> int:\n        return self._start_token_id\n\n    @property\n    def end_token_id(self) -> int:\n        return self._end_token_id\n\n    def _init_vocab(self) -> None:\n        self._vocab = {\n            self._padding_id: self._padding_token,\n            self._cls_id: self._cls_token,\n            self._sep_id: self._sep_token,\n            self._start_token_id: self._start_token,\n            self._end_token_id: self._end_token,\n            self._unknown_token_id: self._unknown_token,\n        }\n\n    def fit(self, corpus: List[str]) -> Self:\n        self._init_vocab()\n        flat_corpus = \"\\n\".join(corpus)\n        for char in set(flat_corpus):\n            if char in self._vocab.values():\n                continue\n            self._vocab[len(self._vocab)] = char\n        return self\n\n    def tokenize_text(self, text: str | List[str]) -> List[str] | List[List[str]]:\n        if isinstance(text, str):\n            return self._tokenize_text(text)\n        assert isinstance(text, list), \"`text` should be str or List[str]\"\n        return [self._tokenize_text(chunk) for chunk in text]\n\n    def tokenize_ids(self, text: str | List[str]) -> List[int] | List[List[int]]:\n        if isinstance(text, str):\n            return self._tokenize_ids(text)\n        assert isinstance(text, list), \"`text` should be str or List[str]\"\n        return [self._tokenize_ids(chunk) for chunk in text]\n\n    def decode(self, tokens: List[int]) -> str:\n        content = []\n        for token in tokens:\n            if token in [self._padding_id, self._cls_id, self._sep_id, self._start_token_id, self._end_token_id, self._unknown_token_id]:\n                continue\n            content.append(\n                self._vocab.get(token, self._unknown_token)\n            )\n        return \"\".join(content)\n\n    def _tokenize_text(self, text: str) -> List[str]:\n        tokens = [self._start_token]\n        reverse_vocab = self.reverse_vocab\n        for char in list(text):\n            if char in reverse_vocab:\n               tokens.append(char)\n            else:\n                tokens.append(self._unknown_token)\n        tokens.append(self._end_token)\n        return tokens\n\n    def _tokenize_ids(self, text: str) -> List[int]:\n        tokens = self._tokenize_text(text)\n        reversed_vocab = self.reverse_vocab\n        tokens_ids = [reversed_vocab[token] for token in tokens]\n        return tokens_ids","metadata":{"id":"7d2944cb","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:32.496964Z","iopub.execute_input":"2025-12-14T18:51:32.497577Z","iopub.status.idle":"2025-12-14T18:51:32.508137Z","shell.execute_reply.started":"2025-12-14T18:51:32.497552Z","shell.execute_reply":"2025-12-14T18:51:32.507450Z"}},"outputs":[],"execution_count":12},{"id":"23d63ab4","cell_type":"code","source":"names = pl.read_parquet(\"names.parquet\")\nsurnames = pl.read_parquet(\"surnames.parquet\")\n\ndef get_persons(names: pl.DataFrame, surnames: pl.DataFrame, n: int = 100) -> List[str]:\n    persons = []\n    for _ in range(n):\n        sex = np.random.choice([\"m\", \"f\"]).item()\n        name = names.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n        surname = surnames.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n        persons.append(f\"{name} {surname}\")\n    return persons\n\ncorpus = get_persons(names, surnames, 10_000)\ncorpus[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23d63ab4","outputId":"c3b5be4d-7fc5-4975-d3d2-65f37cb7b22b","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:35.761748Z","iopub.execute_input":"2025-12-14T18:51:35.762226Z","iopub.status.idle":"2025-12-14T18:51:53.121576Z","shell.execute_reply.started":"2025-12-14T18:51:35.762204Z","shell.execute_reply":"2025-12-14T18:51:53.120883Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['Прасковья Подобутова',\n 'Валентина Скумина',\n 'Аркадий Гуйтов',\n 'София Ежеметьева',\n 'Матвей Бутылкин',\n 'Марк Скворцов',\n 'Арсентий Шмаилов',\n 'Полина Гульцова',\n 'София Стадник-Виноградова',\n 'Федосья Силевцова']"},"metadata":{}}],"execution_count":13},{"id":"6bc28635","cell_type":"code","source":"tokenizer = CharTokenizer().fit(corpus)","metadata":{"id":"6bc28635","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:53.122680Z","iopub.execute_input":"2025-12-14T18:51:53.122936Z","iopub.status.idle":"2025-12-14T18:51:53.136217Z","shell.execute_reply.started":"2025-12-14T18:51:53.122919Z","shell.execute_reply":"2025-12-14T18:51:53.135522Z"}},"outputs":[],"execution_count":14},{"id":"9262c9c0","cell_type":"code","source":"tokenizer.vocab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9262c9c0","outputId":"6904ef59-cfcc-4298-f596-44815f71d4de","jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:53.136913Z","iopub.execute_input":"2025-12-14T18:51:53.137140Z","iopub.status.idle":"2025-12-14T18:51:53.154659Z","shell.execute_reply.started":"2025-12-14T18:51:53.137120Z","shell.execute_reply":"2025-12-14T18:51:53.153846Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{0: '<PAD>',\n 1: '<CLS>',\n 2: '<SEP>',\n 3: '<s>',\n 4: '</s>',\n 5: '<UNK>',\n 6: 'й',\n 7: 'Ш',\n 8: 'а',\n 9: 'в',\n 10: 'я',\n 11: 'С',\n 12: 'х',\n 13: 'И',\n 14: 'В',\n 15: 'Э',\n 16: 'Н',\n 17: 'О',\n 18: 'Д',\n 19: 'щ',\n 20: 'ъ',\n 21: 'з',\n 22: 'Т',\n 23: 'т',\n 24: 'ё',\n 25: 'Ч',\n 26: 'р',\n 27: 'п',\n 28: 'p',\n 29: '0',\n 30: 'е',\n 31: 'Ф',\n 32: '-',\n 33: 'А',\n 34: 'ш',\n 35: 'Ю',\n 36: 'З',\n 37: 'Ц',\n 38: 'К',\n 39: 'ф',\n 40: 'у',\n 41: 'ж',\n 42: 'и',\n 43: 'Б',\n 44: 'Е',\n 45: 'C',\n 46: 'н',\n 47: '`',\n 48: 'ы',\n 49: '\\n',\n 50: 'Я',\n 51: 'П',\n 52: 'о',\n 53: 'б',\n 54: 'Щ',\n 55: 'Р',\n 56: 'М',\n 57: 'Г',\n 58: 'м',\n 59: 'У',\n 60: 'h',\n 61: 'д',\n 62: 'ц',\n 63: 'г',\n 64: ',',\n 65: '.',\n 66: 'Х',\n 67: 'с',\n 68: 'Ж',\n 69: 'э',\n 70: 'л',\n 71: 'ь',\n 72: 'Л',\n 73: 'ч',\n 74: ' ',\n 75: 'к',\n 76: 'ю'}"},"metadata":{}}],"execution_count":15},{"id":"f8883ab5","cell_type":"code","source":"class SimpleTextDataset(Dataset):\n    def __init__(\n        self,\n        corpus: List[str],\n        fitted_tokenizer: CharTokenizer,\n        max_seq_length: int = 100,\n    ):\n        self._data: List[List[int]] = []\n\n        for sentence in corpus:\n            x = fitted_tokenizer.tokenize_ids(sentence[:max_seq_length - 2])\n            self._data.append(x)\n\n    def __len__(self) -> int:\n        return len(self._data)\n\n    def __getitem__(self, idx: int) -> Tuple[List[int], List[int]]:\n        return torch.LongTensor(self._data[idx])\n","metadata":{"id":"f8883ab5","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:53.156408Z","iopub.execute_input":"2025-12-14T18:51:53.156800Z","iopub.status.idle":"2025-12-14T18:51:53.168579Z","shell.execute_reply.started":"2025-12-14T18:51:53.156783Z","shell.execute_reply":"2025-12-14T18:51:53.167872Z"}},"outputs":[],"execution_count":16},{"id":"b740a5df","cell_type":"code","source":"def collate(data: List[torch.Tensor]):\n    x = [torch.LongTensor(seq) for seq in data]\n    return nn.utils.rnn.pad_sequence(x, batch_first=True)","metadata":{"id":"b740a5df","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:53.169436Z","iopub.execute_input":"2025-12-14T18:51:53.169722Z","iopub.status.idle":"2025-12-14T18:51:53.185810Z","shell.execute_reply.started":"2025-12-14T18:51:53.169705Z","shell.execute_reply":"2025-12-14T18:51:53.185180Z"}},"outputs":[],"execution_count":17},{"id":"083643c1","cell_type":"code","source":"VOCAB_SIZE = len(tokenizer.vocab)\nBATCH_SIZE = 256\nMAX_SEQ_LEN = 200\nN_LAYERS = 6\nEMBEDDING_SIZE = 64\nNUM_HEADS = 8\nNUM_KV_GROUPS = 2\nNUM_EXPERTS = 16\nNUM_EXPERTS_PER_TOKEN = 2\nHEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\nFCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\nMTP_K = 3\nn_epoch = 20","metadata":{"id":"083643c1","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:53.186353Z","iopub.execute_input":"2025-12-14T18:51:53.186619Z","iopub.status.idle":"2025-12-14T18:51:53.198165Z","shell.execute_reply.started":"2025-12-14T18:51:53.186589Z","shell.execute_reply":"2025-12-14T18:51:53.197572Z"}},"outputs":[],"execution_count":18},{"id":"5b689383","cell_type":"code","source":"dataset = SimpleTextDataset(\n    corpus=corpus,\n    fitted_tokenizer=tokenizer,\n    max_seq_length=MAX_SEQ_LEN,\n)\ndataloader = DataLoader(\n    dataset=dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=collate\n)","metadata":{"id":"5b689383","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:54.419629Z","iopub.execute_input":"2025-12-14T18:51:54.419941Z","iopub.status.idle":"2025-12-14T18:51:54.550154Z","shell.execute_reply.started":"2025-12-14T18:51:54.419919Z","shell.execute_reply":"2025-12-14T18:51:54.549317Z"}},"outputs":[],"execution_count":19},{"id":"38d11b09","cell_type":"code","source":"next(iter(dataloader)).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38d11b09","outputId":"a60bb068-cd6d-47cc-e207-27a7663089cf","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:51:56.555249Z","iopub.execute_input":"2025-12-14T18:51:56.555968Z","iopub.status.idle":"2025-12-14T18:51:56.569576Z","shell.execute_reply.started":"2025-12-14T18:51:56.555940Z","shell.execute_reply":"2025-12-14T18:51:56.568864Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"torch.Size([256, 27])"},"metadata":{}}],"execution_count":20},{"id":"2313eee5","cell_type":"code","source":"transformer_mtp = MTPTransformer(\n    vocab_size=VOCAB_SIZE,\n    n_layers=N_LAYERS,\n    embedding_size=EMBEDDING_SIZE,\n    num_heads=NUM_HEADS,\n    num_experts=NUM_EXPERTS,\n    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n    head_embedding_size=HEAD_EMBEDDING_SIZE,\n    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n    dropout = 0.15,\n    mtp_k = MTP_K\n)\n\noptimizer = Adam(transformer_mtp.parameters(), lr=4e-3)\nloss_func = nn.CrossEntropyLoss(reduction='none')","metadata":{"id":"2313eee5","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:13:42.988468Z","iopub.execute_input":"2025-12-14T19:13:42.989061Z","iopub.status.idle":"2025-12-14T19:13:43.077139Z","shell.execute_reply.started":"2025-12-14T19:13:42.989039Z","shell.execute_reply":"2025-12-14T19:13:43.076184Z"}},"outputs":[],"execution_count":26},{"id":"4a5f7551","cell_type":"code","source":"import math\nimport torch\nimport torch.nn.functional as F\n\ndef compute_perplexity(model, dataloader, loss_func, device):\n    model.eval()\n    total_loss = 0.0\n    total_tokens = 0\n\n    with torch.no_grad():\n        for x in dataloader:\n            x = x.to(device)  # [B, T]\n            \n            # Создаем attention mask\n            attention_mask = (x != 0).float()  # [B, T]\n            \n            curr_x = x[:, :-1]        # [B, T-1] вход\n            next_x = x[:, 1:]         # [B, T-1] цели\n            \n            # Передаем маску в модель\n            logits = model(curr_x, attention_mask=attention_mask[:, :-1])  # [B, L, K, V]\n            B, L, K, V = logits.shape\n\n            # Только main head (k=0)\n            logits_main = logits[:, :, 0, :]      # [B, L, V]\n            targets = next_x[:, :L]               # [B, L]\n\n            # Маска для валидных токенов (не PAD и не EOS)\n            mask = (targets != 0) & (targets != 4)  # [B, L]\n\n            if mask.any():\n                logits_flat = logits_main[mask]     # [N, V]\n                targets_flat = targets[mask]        # [N]\n\n                ce = F.cross_entropy(\n                    logits_flat,\n                    targets_flat,\n                    reduction='sum'\n                )\n                total_loss += ce.item()\n                total_tokens += mask.sum().item()\n\n    if total_tokens == 0:\n        return float('inf')\n\n    mean_nll = total_loss / total_tokens\n    return math.exp(mean_nll)","metadata":{"id":"4a5f7551","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:57:21.153025Z","iopub.execute_input":"2025-12-14T18:57:21.153668Z","iopub.status.idle":"2025-12-14T18:57:21.160283Z","shell.execute_reply.started":"2025-12-14T18:57:21.153643Z","shell.execute_reply":"2025-12-14T18:57:21.159507Z"}},"outputs":[],"execution_count":22},{"id":"3d012cda-fad7-4c6c-a5d6-5019027e251b","cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\n\ndef train_and_collect(model, n_epoch, dataloader, loss_func, optimizer, num_experts, device, mtp_lambda=0.3):\n    epoch_loss = []\n    expert_usage_list = []\n    ppl_list = []\n\n    for epoch in range(n_epoch):\n        model.train()\n        losses = []\n        print(f\"Epoch {epoch+1}\")\n\n        all_layers_topk_indices = []\n\n        for x in tqdm(dataloader):\n            B, T = x.shape\n            K = model.mtp_k\n            V = model.vocab_size  # Размерность словаря (предположим, что ты знаешь V заранее)\n\n            # === НОВОЕ: Создаем attention mask ===\n            attention_mask = (x != 0).float().to(device)  # [B, T]\n\n            # Вход для модели\n            curr_x = x[:, :T-K].to(device)      # [B, T-K]\n            full_next_x = x[:, 1:T].to(device)  # [B, T-1]\n            \n            # === ПЕРЕДАЕМ МАСКУ В МОДЕЛЬ ===\n            logits = model(curr_x, attention_mask=attention_mask[:, :T-K], use_cache=False)\n            B_out, L, K_out, V = logits.shape\n\n            # ===== Main loss =====\n            main_logits = logits[:, :, 0, :].reshape(-1, V)\n            main_targets = full_next_x[:, :L].reshape(-1)\n\n            main_mask = main_targets != 0\n            main_loss_per_token = loss_func(main_logits, main_targets)\n            main_loss_per_token = main_loss_per_token[main_mask]\n\n            main_loss = (\n                main_loss_per_token.mean()\n                if main_loss_per_token.numel() > 0\n                else torch.tensor(0.0, device=device)\n            )\n\n            # ===== MTP loss =====\n            mtp_loss = 0.0\n\n            for k in range(1, K_out):\n                mtp_logits = logits[:, :, k, :].reshape(-1, V)\n                mtp_targets = full_next_x[:, k:k+L].reshape(-1)\n\n                mtp_mask = mtp_targets != 0\n                if mtp_mask.sum() == 0:\n                    continue\n\n                loss_per_token = loss_func(mtp_logits, mtp_targets)\n                mtp_loss += loss_per_token[mtp_mask].mean()\n\n            # Скалируем MTP loss по количеству слоев\n            mtp_loss = (mtp_loss / max(1, K_out - 1)) * mtp_lambda\n\n            # Общая потеря\n            total_loss = main_loss + mtp_loss\n            losses.append(total_loss.item())\n\n            # MoE usage (без изменений)\n            batch_indices = []\n            for layer in model.main_layers:\n                if hasattr(layer._fcnn, 'last_topk_indices') and layer._fcnn.last_topk_indices is not None:\n                    batch_indices.append(layer._fcnn.last_topk_indices.detach())\n            for layer in model.mtp_layers:\n                if hasattr(layer._fcnn, 'last_topk_indices') and layer._fcnn.last_topk_indices is not None:\n                    batch_indices.append(layer._fcnn.last_topk_indices.detach())\n\n            if batch_indices:\n                combined_batch = torch.cat(batch_indices, dim=0)\n                all_layers_topk_indices.append(combined_batch)\n\n            # Backpropagation\n            optimizer.zero_grad()\n            total_loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        # Подсчет потерь по эпохам\n        epoch_loss.append(np.mean(losses))\n\n        # Подсчет использования экспертов\n        if all_layers_topk_indices:\n            all_topk_flat = torch.cat([t.reshape(-1) for t in all_layers_topk_indices])\n            usage = np.array([(all_topk_flat.cpu().numpy() == i).sum() for i in range(num_experts)])\n        else:\n            usage = np.zeros(num_experts, dtype=int)\n\n        expert_usage_list.append(usage)\n\n        # Подсчет PPL (перплексии)\n        ppl = compute_perplexity(model, dataloader, loss_func, device)\n        ppl_list.append(ppl)\n\n        # Печать результата по эпохам\n        print(f\"Loss: {epoch_loss[-1]:.4f} | PPL: {ppl:.4f}\")\n\n    return epoch_loss, expert_usage_list, ppl_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:57:24.500938Z","iopub.execute_input":"2025-12-14T18:57:24.501428Z","iopub.status.idle":"2025-12-14T18:57:24.515061Z","shell.execute_reply.started":"2025-12-14T18:57:24.501406Z","shell.execute_reply":"2025-12-14T18:57:24.514249Z"}},"outputs":[],"execution_count":23},{"id":"7a275895","cell_type":"code","source":"device = \"cuda\"\ntransformer_mtp.to(device)\n\nloss_mha, usage_mha, ppl_mha = train_and_collect(\n  transformer_mtp, 100, dataloader, loss_func, optimizer, NUM_EXPERTS, device\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7a275895","outputId":"a2c11e3a-57ab-44a9-de35-b51cdd292e8c","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:13:51.566521Z","iopub.execute_input":"2025-12-14T19:13:51.567013Z","iopub.status.idle":"2025-12-14T19:31:08.455396Z","shell.execute_reply.started":"2025-12-14T19:13:51.566989Z","shell.execute_reply":"2025-12-14T19:31:08.454769Z"}},"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 7.2243 | PPL: 9.9227\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 2.5768 | PPL: 6.0466\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 2.1514 | PPL: 5.3623\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.9813 | PPL: 4.6522\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.9048 | PPL: 4.3150\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8536 | PPL: 4.3105\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8329 | PPL: 4.2846\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8141 | PPL: 4.2139\nEpoch 9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7945 | PPL: 4.0925\nEpoch 10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7745 | PPL: 4.2062\nEpoch 11\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7592 | PPL: 4.0204\nEpoch 12\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7542 | PPL: 4.0525\nEpoch 13\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7408 | PPL: 3.9405\nEpoch 14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7298 | PPL: 4.0125\nEpoch 15\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7200 | PPL: 3.9611\nEpoch 16\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7121 | PPL: 3.9973\nEpoch 17\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7059 | PPL: 3.8247\nEpoch 18\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7014 | PPL: 3.7937\nEpoch 19\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6936 | PPL: 3.7630\nEpoch 20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6797 | PPL: 3.7258\nEpoch 21\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6803 | PPL: 3.7341\nEpoch 22\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6723 | PPL: 3.6689\nEpoch 23\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6641 | PPL: 3.6793\nEpoch 24\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6577 | PPL: 3.6462\nEpoch 25\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6568 | PPL: 3.5997\nEpoch 26\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6469 | PPL: 3.5913\nEpoch 27\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6364 | PPL: 3.5578\nEpoch 28\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6312 | PPL: 3.5322\nEpoch 29\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6234 | PPL: 3.4939\nEpoch 30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6236 | PPL: 3.4795\nEpoch 31\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6117 | PPL: 3.4678\nEpoch 32\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6088 | PPL: 3.4164\nEpoch 33\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6008 | PPL: 3.4204\nEpoch 34\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6007 | PPL: 3.3589\nEpoch 35\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5958 | PPL: 3.3613\nEpoch 36\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5875 | PPL: 3.3482\nEpoch 37\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5823 | PPL: 3.3467\nEpoch 38\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5719 | PPL: 3.3032\nEpoch 39\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5662 | PPL: 3.3136\nEpoch 40\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5661 | PPL: 3.2476\nEpoch 41\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5512 | PPL: 3.2206\nEpoch 42\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5474 | PPL: 3.2044\nEpoch 43\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5420 | PPL: 3.1893\nEpoch 44\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5421 | PPL: 3.1478\nEpoch 45\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5316 | PPL: 3.1370\nEpoch 46\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5259 | PPL: 3.1243\nEpoch 47\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5185 | PPL: 3.0938\nEpoch 48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5121 | PPL: 3.0763\nEpoch 49\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5057 | PPL: 3.0423\nEpoch 50\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5032 | PPL: 2.9948\nEpoch 51\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4880 | PPL: 2.9752\nEpoch 52\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4876 | PPL: 2.9592\nEpoch 53\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4785 | PPL: 2.9682\nEpoch 54\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4782 | PPL: 2.9265\nEpoch 55\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4695 | PPL: 2.8871\nEpoch 56\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4644 | PPL: 2.8850\nEpoch 57\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4533 | PPL: 2.8454\nEpoch 58\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4458 | PPL: 2.8402\nEpoch 59\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4411 | PPL: 2.8150\nEpoch 60\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4408 | PPL: 2.7876\nEpoch 61\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4350 | PPL: 2.7688\nEpoch 62\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4237 | PPL: 2.7477\nEpoch 63\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4246 | PPL: 2.7506\nEpoch 64\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4127 | PPL: 2.7335\nEpoch 65\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4121 | PPL: 2.7098\nEpoch 66\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3988 | PPL: 2.6884\nEpoch 67\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3981 | PPL: 2.6579\nEpoch 68\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3895 | PPL: 2.6671\nEpoch 69\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3880 | PPL: 2.6312\nEpoch 70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3780 | PPL: 2.6004\nEpoch 71\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3790 | PPL: 2.6170\nEpoch 72\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3707 | PPL: 2.5863\nEpoch 73\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3642 | PPL: 2.5581\nEpoch 74\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3624 | PPL: 2.5563\nEpoch 75\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3542 | PPL: 2.5147\nEpoch 76\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3503 | PPL: 2.5081\nEpoch 77\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3431 | PPL: 2.5048\nEpoch 78\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3360 | PPL: 2.4660\nEpoch 79\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3270 | PPL: 2.4567\nEpoch 80\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3209 | PPL: 2.4608\nEpoch 81\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3209 | PPL: 2.4251\nEpoch 82\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3118 | PPL: 2.4141\nEpoch 83\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3089 | PPL: 2.4051\nEpoch 84\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3008 | PPL: 2.3844\nEpoch 85\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2937 | PPL: 2.3730\nEpoch 86\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2920 | PPL: 2.3493\nEpoch 87\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2875 | PPL: 2.3700\nEpoch 88\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2868 | PPL: 2.3558\nEpoch 89\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2762 | PPL: 2.3559\nEpoch 90\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2817 | PPL: 2.3350\nEpoch 91\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2682 | PPL: 2.3087\nEpoch 92\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2603 | PPL: 2.3049\nEpoch 93\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2647 | PPL: 2.2819\nEpoch 94\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2499 | PPL: 2.2612\nEpoch 95\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2499 | PPL: 2.2709\nEpoch 96\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2568 | PPL: 2.2608\nEpoch 97\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2368 | PPL: 2.2350\nEpoch 98\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2372 | PPL: 2.2332\nEpoch 99\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2402 | PPL: 2.2329\nEpoch 100\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:07<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2263 | PPL: 2.2195\n","output_type":"stream"}],"execution_count":27},{"id":"_9vDkaImiBDG","cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = range(1, len(loss_mha)+1)\n\nfig, ax1 = plt.subplots(figsize=(8,5))\n\n# ===== Loss =====\nax1.plot(epochs, loss_mha, 'b-o', label='Loss MHA')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss', color='b')\nax1.tick_params(axis='y', labelcolor='b')\n\n# ===== PPL =====\nax2 = ax1.twinx()  # создаем вторую ось Y\nax2.plot(epochs, ppl_mha, 'r-o', label='PPL MHA')\nax2.set_ylabel('Perplexity', color='r')\nax2.tick_params(axis='y', labelcolor='r')\n\n# ===== легенда =====\nlines, labels = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines + lines2, labels + labels2, loc='upper right')\n\nplt.title(\"Loss & Perplexity Comparison\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"_9vDkaImiBDG","outputId":"6b57ce22-c13f-4d7c-e80b-9af50bfada33","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:31:12.365200Z","iopub.execute_input":"2025-12-14T19:31:12.365757Z","iopub.status.idle":"2025-12-14T19:31:12.705966Z","shell.execute_reply.started":"2025-12-14T19:31:12.365730Z","shell.execute_reply":"2025-12-14T19:31:12.705333Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":28},{"id":"f8821cf7","cell_type":"code","source":"def model_memory_size(model, input_dtype=torch.float32):\n    total_params = 0\n    total_grads = 0\n    for param in model.parameters():\n        # Calculate total number of elements per parameter\n        param_size = param.numel()\n        total_params += param_size\n        # Check if gradients are stored for this parameter\n        if param.requires_grad:\n            total_grads += param_size\n\n    # Calculate buffer size (non-parameters that require memory)\n    total_buffers = sum(buf.numel() for buf in model.buffers())\n\n    # Size in bytes = (Number of elements) * (Size of each element in bytes)\n    # We assume parameters and gradients are stored in the same type as input dtype\n    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n\n    # Convert bytes to megabytes\n    total_memory_mb = total_memory_bytes / (1024**2)\n\n    return total_memory_mb\n\nprint(f\"float32 (PyTorch default): {model_memory_size(transformer_mtp, input_dtype=torch.float32):.4f} MB\")\nprint(f\"bfloat16: {model_memory_size(transformer_mtp, input_dtype=torch.bfloat16):.4f} MB\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8821cf7","outputId":"f32588e5-f46a-4662-94ac-977504f2e6b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:31:20.378109Z","iopub.execute_input":"2025-12-14T19:31:20.378857Z","iopub.status.idle":"2025-12-14T19:31:20.388786Z","shell.execute_reply.started":"2025-12-14T19:31:20.378831Z","shell.execute_reply":"2025-12-14T19:31:20.388027Z"}},"outputs":[{"name":"stdout","text":"float32 (PyTorch default): 48.9883 MB\nbfloat16: 24.4941 MB\n","output_type":"stream"}],"execution_count":29},{"id":"059c0d5b","cell_type":"markdown","source":"# TEST MODEL","metadata":{"id":"059c0d5b"}},{"id":"9b6bfc0f-4a2a-4e4e-b6bb-2e7fddc9f211","cell_type":"code","source":"def generate(\n    model: nn.Module,\n    text_input: str,\n    tokenizer: CharTokenizer,\n    max_steps: int = 100,\n    device: str = \"cuda\",\n    temperature: float = 1.0,\n    top_k: int = 50\n) -> str:\n    model.eval()\n    model.to(device)\n\n    # Токенизируем вход\n    input_tokens = tokenizer.tokenize_ids(text_input)\n    x = torch.tensor([input_tokens], dtype=torch.long, device=device)  # [1, T]\n\n    generated_tokens = input_tokens.copy()\n\n    for step in range(max_steps):\n        with torch.no_grad():\n            # **КЛЮЧЕВОЕ: используем ТОЛЬКО main prediction k=0**\n            logits = model(x)  # [1, L, K, V]\n\n            # Берем logits с последней позиции, main head (k=0)\n            next_logits = logits[0, -1, 0] / temperature  # [V]\n\n            # Top-K sampling\n            if top_k > 0:\n                v, _ = torch.topk(next_logits, min(top_k, next_logits.size(-1)))\n                next_logits[torch.lt(next_logits, v[0])] = -float('Inf')\n\n            probs = F.softmax(next_logits, dim=-1)\n            next_token = torch.multinomial(probs, num_samples=1)\n\n        next_token_id = next_token.item()\n        generated_tokens.append(next_token_id)\n\n        # Останавливаемся на EOS\n        if next_token_id == 4:  # <EOS>\n            break\n\n        # Добавляем токен к последовательности\n        x = torch.cat([x, next_token.unsqueeze(0)], dim=1)\n\n    return tokenizer.decode(generated_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:32:27.299126Z","iopub.execute_input":"2025-12-14T19:32:27.299740Z","iopub.status.idle":"2025-12-14T19:32:27.306623Z","shell.execute_reply.started":"2025-12-14T19:32:27.299714Z","shell.execute_reply":"2025-12-14T19:32:27.305940Z"}},"outputs":[],"execution_count":34},{"id":"e8016cab","cell_type":"code","source":"transformer_mtp.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8016cab","outputId":"0ea3718b-9467-418c-9957-6f7b858d1dd7","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:32:27.818553Z","iopub.execute_input":"2025-12-14T19:32:27.818790Z","iopub.status.idle":"2025-12-14T19:32:27.827061Z","shell.execute_reply.started":"2025-12-14T19:32:27.818772Z","shell.execute_reply":"2025-12-14T19:32:27.826469Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"MTPTransformer(\n  (_embeddings): Embedding(77, 64, padding_idx=0)\n  (main_layers): ModuleList(\n    (0-5): 6 x DecoderLayer(\n      (_mla): MultiHeadLatentAttention(\n        (W_Q): Linear(in_features=64, out_features=64, bias=False)\n        (W_C): Linear(in_features=64, out_features=16, bias=False)\n        (W_K): Linear(in_features=16, out_features=64, bias=False)\n        (W_V): Linear(in_features=16, out_features=64, bias=False)\n        (W_O): Linear(in_features=64, out_features=64, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (_fcnn): MoENoisyTopKGateFeedForward(\n        (_gate): Linear(in_features=64, out_features=16, bias=False)\n        (_noise_linear): Linear(in_features=64, out_features=16, bias=False)\n        (_fc1): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc2): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc3): ModuleList(\n          (0-15): 16 x Linear(in_features=256, out_features=64, bias=False)\n        )\n      )\n      (_rms_norm1): RMSNorm()\n      (_rms_norm2): RMSNorm()\n      (_dropout): Dropout(p=0.15, inplace=False)\n    )\n  )\n  (mtp_layers): ModuleList(\n    (0-1): 2 x DecoderLayer(\n      (_mla): MultiHeadLatentAttention(\n        (W_Q): Linear(in_features=64, out_features=64, bias=False)\n        (W_C): Linear(in_features=64, out_features=16, bias=False)\n        (W_K): Linear(in_features=16, out_features=64, bias=False)\n        (W_V): Linear(in_features=16, out_features=64, bias=False)\n        (W_O): Linear(in_features=64, out_features=64, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (_fcnn): MoENoisyTopKGateFeedForward(\n        (_gate): Linear(in_features=64, out_features=16, bias=False)\n        (_noise_linear): Linear(in_features=64, out_features=16, bias=False)\n        (_fc1): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc2): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc3): ModuleList(\n          (0-15): 16 x Linear(in_features=256, out_features=64, bias=False)\n        )\n      )\n      (_rms_norm1): RMSNorm()\n      (_rms_norm2): RMSNorm()\n      (_dropout): Dropout(p=0.15, inplace=False)\n    )\n  )\n  (_rms_norm): RMSNorm()\n  (projections): ModuleList(\n    (0-1): 2 x Linear(in_features=128, out_features=64, bias=True)\n  )\n  (_logits): Linear(in_features=64, out_features=77, bias=False)\n)"},"metadata":{}}],"execution_count":35},{"id":"f4a4c3f8","cell_type":"code","source":"generate(\n    model=transformer_mtp,\n    text_input=\"Красотка\",\n    tokenizer=tokenizer,\n    device=device,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f4a4c3f8","outputId":"bc9dc6e3-ae36-410f-8cc6-fe2670e664ed","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:33:05.155757Z","iopub.execute_input":"2025-12-14T19:33:05.156404Z","iopub.status.idle":"2025-12-14T19:33:06.261269Z","shell.execute_reply.started":"2025-12-14T19:33:05.156380Z","shell.execute_reply":"2025-12-14T19:33:06.260691Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'Красоткаиннрятаа и  БшББуиуурмттхаооанвв'"},"metadata":{}}],"execution_count":41},{"id":"1f80b1e3-0c21-437b-84c6-47f2351f2416","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}