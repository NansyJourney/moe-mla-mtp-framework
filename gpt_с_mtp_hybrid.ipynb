{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14154906,"sourceType":"datasetVersion","datasetId":9021889}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5f84fcbd","cell_type":"markdown","source":"# MULTIHEAD ATTENTION","metadata":{"id":"5f84fcbd"}},{"id":"9974e3de","cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n\nimport re\nfrom typing import List, Dict, Any, Tuple, Optional, Mapping, Set, Self, NamedTuple, TypedDict","metadata":{"id":"9974e3de","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:17:22.768750Z","iopub.execute_input":"2025-12-15T18:17:22.768941Z","iopub.status.idle":"2025-12-15T18:17:29.820159Z","shell.execute_reply.started":"2025-12-15T18:17:22.768924Z","shell.execute_reply":"2025-12-15T18:17:29.819370Z"}},"outputs":[],"execution_count":1},{"id":"11f7c25d","cell_type":"code","source":"def fix_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)","metadata":{"id":"11f7c25d","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:17:43.124379Z","iopub.execute_input":"2025-12-15T18:17:43.125126Z","iopub.status.idle":"2025-12-15T18:17:43.128595Z","shell.execute_reply.started":"2025-12-15T18:17:43.125097Z","shell.execute_reply":"2025-12-15T18:17:43.128017Z"}},"outputs":[],"execution_count":2},{"id":"c666d27f","cell_type":"markdown","source":"# BUILD TRANSFORMER","metadata":{"id":"c666d27f"}},{"id":"7e01f273","cell_type":"code","source":"class RMSNorm(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        eps: float = 1e-6,\n        bias: bool = False,\n    ) -> None:\n        super().__init__()\n        self._eps = eps\n        self._scale = nn.Parameter(torch.ones(embedding_size))\n        self._shift = nn.Parameter(torch.zeros(embedding_size)) if bias else None\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        input_dtype = x.dtype\n\n        variance = x.pow(2).mean(dim=-1, keepdim=True)\n        norm_x = x * torch.rsqrt(variance + self._eps)\n        norm_x = norm_x * self._scale\n\n        if self._shift is not None:\n            norm_x = norm_x + self._shift\n\n        return norm_x.to(input_dtype)","metadata":{"id":"7e01f273","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:17:45.946934Z","iopub.execute_input":"2025-12-15T18:17:45.947455Z","iopub.status.idle":"2025-12-15T18:17:45.952991Z","shell.execute_reply.started":"2025-12-15T18:17:45.947430Z","shell.execute_reply":"2025-12-15T18:17:45.952274Z"}},"outputs":[],"execution_count":3},{"id":"987ac0a8","cell_type":"code","source":"class MoENoisyTopKGateFeedForward(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        moe_hidden_size: int,\n        noisy_gating: bool = True,\n    ) -> None:\n        super().__init__()\n\n        self._num_experts_per_tok = num_experts_per_token\n        self._num_experts = num_experts\n        self._embedding_size = embedding_size\n        self.noisy_gating = noisy_gating\n        self._gate = nn.Linear(embedding_size, num_experts, bias=False)\n\n        # extra projection for Noisy Top-k Gating\n        if noisy_gating:\n            self._noise_linear = nn.Linear(embedding_size, num_experts, bias=False)\n\n        self._fc1 = nn.ModuleList([\n            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n            for _ in range(num_experts)\n        ])\n        self._fc2 = nn.ModuleList([\n            nn.Linear(embedding_size, moe_hidden_size, bias=False)\n            for _ in range(num_experts)\n        ])\n        self._fc3 = nn.ModuleList([\n            nn.Linear(moe_hidden_size, embedding_size, bias=False)\n            for _ in range(num_experts)\n        ])\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        scores = self._gate(x)  # (b, seq_len, num_experts)\n\n        # ---------- 2. Add noise for Noisy Top-k ----------\n        if self.noisy_gating and self.training:\n            raw_noise_std = self._noise_linear(x)              # (B, S, E)\n            noise_std = F.softplus(raw_noise_std) + 1e-9       # H(x) = softplus(...)\n            noise = torch.randn_like(scores) * noise_std       # N(0, softplus(...))\n            scores = scores + noise                                 # noisy top-k\n\n        # ---------- 3. Top-k selection ----------\n        topk_scores, topk_indices = torch.topk(\n            scores, self._num_experts_per_tok, dim=-1\n        )\n        topk_probs = torch.softmax(topk_scores, dim=-1)\n\n        self.last_topk_indices = topk_indices.detach()\n\n        batch, seq_len, _ = x.shape\n        x_flat = x.reshape(batch * seq_len, -1)\n        out_flat = torch.zeros(batch * seq_len, self._embedding_size,\n                               device=x.device, dtype=x.dtype)\n\n        topk_indices_flat = topk_indices.reshape(-1, self._num_experts_per_tok)\n        topk_probs_flat   = topk_probs.reshape(-1, self._num_experts_per_tok)\n\n        unique_experts = torch.unique(topk_indices_flat)\n\n        for expert_id_tensor in unique_experts:\n            expert_id = int(expert_id_tensor.item())\n            mask = topk_indices_flat == expert_id\n            if not mask.any():\n                continue\n\n            token_mask = mask.any(dim=-1)\n            selected_idx = token_mask.nonzero(as_tuple=False).squeeze(-1)\n            if selected_idx.numel() == 0:\n                continue\n\n            expert_input = x_flat.index_select(0, selected_idx)\n\n            hidden = (\n                torch.nn.functional.silu(self._fc1[expert_id](expert_input)) *\n                self._fc2[expert_id](expert_input)\n            )\n            expert_out = self._fc3[expert_id](hidden)\n\n            mask_selected = mask[selected_idx]\n            slot_indices = mask_selected.int().argmax(dim=-1, keepdim=True)\n\n            selected_probs = torch.gather(\n                topk_probs_flat.index_select(0, selected_idx),\n                dim=-1,\n                index=slot_indices\n            ).squeeze(-1)\n\n            out_flat.index_add_(\n                0,\n                selected_idx,\n                expert_out * selected_probs.unsqueeze(-1)\n            )\n\n        return out_flat.reshape(batch, seq_len, self._embedding_size)","metadata":{"id":"987ac0a8","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:17:47.942639Z","iopub.execute_input":"2025-12-15T18:17:47.942908Z","iopub.status.idle":"2025-12-15T18:17:47.954238Z","shell.execute_reply.started":"2025-12-15T18:17:47.942889Z","shell.execute_reply":"2025-12-15T18:17:47.953494Z"}},"outputs":[],"execution_count":4},{"id":"5bbfa7a0-3898-4e65-bdd4-af4c568604c1","cell_type":"code","source":"class MultiHeadLatentAttention(nn.Module):\n    def __init__(\n        self,\n        num_heads: int,\n        embedding_size: int,\n        head_embedding_size: int,\n        dropout: float,\n        qkv_bias: bool = False,\n        latent_dim: Optional[int] = None,\n    ):\n        super().__init__()\n\n        self.num_heads = num_heads\n        self.head_dim = head_embedding_size\n        self.embedding_size = embedding_size\n        self.d_out = num_heads * head_embedding_size\n\n        # Latent-space dimensionality\n        self.latent_dim = latent_dim if latent_dim is not None else max(16, self.d_out // 8)\n\n        # ---------------------------------------------------------\n        # Unified naming with classical MHA:\n        #   W_Q : Query projection\n        #   W_C : Down-projection → latent \"C\"\n        #   W_K : Up-projection latent → Keys\n        #   W_V : Up-projection latent → Values\n        #   W_O : Output projection\n        # ---------------------------------------------------------\n\n        self.W_Q = nn.Linear(embedding_size, self.d_out, bias=qkv_bias)\n        self.W_C = nn.Linear(embedding_size, self.latent_dim, bias=qkv_bias)\n\n        self.W_K = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n        self.W_V = nn.Linear(self.latent_dim, self.d_out, bias=qkv_bias)\n\n        self.W_O = nn.Linear(self.d_out, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n\n        # Latent KV-cache\n        self.register_buffer(\"cache_c_kv\", None, persistent=False)\n        self.ptr = 0\n\n    def reset_cache(self):\n        self.cache_c_kv = None\n        self.ptr = 0\n\n    @staticmethod\n    def reshape_heads(x, num_heads, head_dim):\n        # (b, T, num_heads * head_dim) → (b, num_heads, T, head_dim)\n        b, T, _ = x.shape\n        return x.view(b, T, num_heads, head_dim).transpose(1, 2).contiguous()\n\n    def forward(self, x, attention_mask=None, use_cache: bool = False):\n        \"\"\"\n        x: (batch, T, embedding_size)\n        \"\"\"\n        b, T, _ = x.shape\n        h = self.num_heads\n        d = self.head_dim\n\n        Q_all = self.W_Q(x)\n        C_new = self.W_C(x)\n\n        if use_cache:\n            if self.cache_c_kv is None:\n                C_total = C_new\n            else:\n                C_total = torch.cat([self.cache_c_kv, C_new], dim=1)\n\n            self.cache_c_kv = C_total\n        else:\n            C_total = C_new\n\n        K_all = self.W_K(C_total)\n        V_all = self.W_V(C_total)\n\n        Q = self.reshape_heads(Q_all, h, d)\n        K = self.reshape_heads(K_all, h, d)\n        V = self.reshape_heads(V_all, h, d)\n\n        attn_scores = torch.matmul(Q, K.transpose(-2, -1))\n\n        T_Q = Q.shape[-2]\n        T_K = K.shape[-2]\n\n        device = Q.device\n\n        if use_cache:\n            q_pos = torch.arange(self.ptr, self.ptr + T_Q, device=device, dtype=torch.long)\n            self.ptr += T_Q\n        else:\n            q_pos = torch.arange(T_Q, device=device, dtype=torch.long)\n            self.ptr = 0\n\n        k_pos = torch.arange(T_K, device=device, dtype=torch.long)\n\n        causal_mask = q_pos.unsqueeze(-1) < k_pos.unsqueeze(0)\n        attn_scores.masked_fill_(causal_mask, -torch.inf)\n\n        attn_weights = torch.softmax(attn_scores / (K.shape[-1]**0.5), dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        context = (attn_weights @ V)\n        context = context.transpose(1, 2).contiguous()\\\n                           .view(b, T, self.d_out)\n\n        out = self.W_O(context)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:17:51.984181Z","iopub.execute_input":"2025-12-15T18:17:51.984481Z","iopub.status.idle":"2025-12-15T18:17:51.997223Z","shell.execute_reply.started":"2025-12-15T18:17:51.984459Z","shell.execute_reply":"2025-12-15T18:17:51.996531Z"}},"outputs":[],"execution_count":5},{"id":"p6eNamhIJWsp","cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(\n        self,\n        embedding_size: int,\n        num_heads: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        head_embedding_size: int,\n        fcnn_hidden_size: int,\n        dropout: float = 0.1,\n    ) -> None:\n        super().__init__()\n\n        self._mla = MultiHeadLatentAttention(\n            embedding_size=embedding_size,\n            num_heads=num_heads,\n            head_embedding_size=head_embedding_size,\n            dropout=dropout\n        )\n\n        self._fcnn = MoENoisyTopKGateFeedForward(\n            embedding_size=embedding_size,\n            num_experts=num_experts,\n            num_experts_per_token=num_experts_per_token,\n            moe_hidden_size=fcnn_hidden_size,\n            noisy_gating=True\n        )\n\n        self._rms_norm1 = RMSNorm(embedding_size)\n        self._rms_norm2 = RMSNorm(embedding_size)\n        self._dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, attention_mask=None, use_cache: bool = False):\n        z = self._rms_norm1(x)\n        z = self._mla(z, attention_mask=attention_mask, use_cache=use_cache)\n        x = x + self._dropout(z)\n\n        z = self._rms_norm2(x)\n        z = self._fcnn(z)\n        return x + self._dropout(z)","metadata":{"id":"p6eNamhIJWsp","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:18:01.812923Z","iopub.execute_input":"2025-12-15T18:18:01.813532Z","iopub.status.idle":"2025-12-15T18:18:01.819530Z","shell.execute_reply.started":"2025-12-15T18:18:01.813509Z","shell.execute_reply":"2025-12-15T18:18:01.818960Z"}},"outputs":[],"execution_count":6},{"id":"4f698b83-3b72-4cd3-9350-e1b59da03315","cell_type":"markdown","source":"Реализуем класс **MTPTransformer**, предназначенный для обучения модели на задаче предсказания следующих трёх токенов последовательности. Алгоритм реализован на основе методологии MTP (Multi-Token Prediction), предложенной в архитектуре DeepSeek.","metadata":{}},{"id":"uZPwLpubxYIb","cell_type":"code","source":"class MTPTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_size: int,\n        n_layers: int,\n        embedding_size: int,\n        num_heads: int,\n        num_experts: int,\n        num_experts_per_token: int,\n        head_embedding_size: int,\n        fcnn_hidden_size: int,\n        dropout: float = 0.1,\n        mtp_k: int = 3,\n        max_seq_len: int = 2048,\n    ) -> None:\n        super().__init__()\n\n        self.vocab_size = vocab_size\n        self.mtp_k = mtp_k\n        self.n_layers = n_layers\n        self.embedding_size = embedding_size\n        self.max_seq_len = max_seq_len\n\n        self._embeddings = nn.Embedding(\n            num_embeddings=vocab_size,\n            embedding_dim=embedding_size,\n            padding_idx=0,\n        )\n\n        self.main_layers = nn.ModuleList([\n            DecoderLayer(\n                embedding_size=embedding_size,\n                num_heads=num_heads,\n                num_experts=num_experts,\n                num_experts_per_token=num_experts_per_token,\n                head_embedding_size=head_embedding_size,\n                fcnn_hidden_size=fcnn_hidden_size,\n                dropout=dropout\n            )\n            for _ in range(n_layers)\n        ])\n\n        self.mtp_layers = nn.ModuleList([\n            nn.ModuleList([\n                DecoderLayer(\n                    embedding_size=embedding_size,\n                    num_heads=num_heads,\n                    num_experts=num_experts,\n                    num_experts_per_token=num_experts_per_token,\n                    head_embedding_size=head_embedding_size,\n                    fcnn_hidden_size=fcnn_hidden_size,\n                    dropout=dropout\n                )\n                for _ in range(n_layers)\n            ])\n            for _ in range(mtp_k - 1)\n        ])\n\n        self._rms_norm = RMSNorm(embedding_size)\n        self.projections = nn.ModuleList([\n            nn.Linear(2 * embedding_size, embedding_size)\n            for _ in range(mtp_k - 1)\n        ])\n\n        self._logits = nn.Linear(embedding_size, vocab_size, bias=False)\n        self._logits.weight = self._embeddings.weight\n\n    def forward(self, x: torch.LongTensor, attention_mask=None, use_cache: bool = False):\n        B, T = x.shape\n\n        # Валидация входа\n        if T < self.mtp_k:\n            raise ValueError(f\"Sequence length {T} must be >= mtp_k={self.mtp_k}\")\n\n        max_seq_len = T - self.mtp_k\n\n        # Эмбеддинги\n        z = self._embeddings(x)\n\n        # Основной путь\n        h_main = z[:, :max_seq_len, :]\n        for layer in self.main_layers:\n            h_main = layer(h_main, attention_mask=attention_mask, use_cache=use_cache)\n\n        logits_main = self._logits(h_main)\n        outputs = [logits_main]\n        h_prev = h_main\n\n        # MTP этапы\n        for k in range(1, self.mtp_k):\n            start_idx = k\n            end_idx = max_seq_len + k\n\n            # Корректная индексация для MTP токенов\n            h_curr_emb = z[:, start_idx:end_idx, :]\n\n            # Нормализация и проекция\n            h_norm = self._rms_norm(h_prev)\n            e_norm = self._rms_norm(h_curr_emb)\n            merged = torch.cat([h_norm, e_norm], dim=-1)\n            h_prime = self.projections[k-1](merged)\n\n            # MTP слой\n            for layer in self.mtp_layers[k-1]:\n                h_prime = layer(h_prime, attention_mask=attention_mask, use_cache=use_cache)\n            h_k = h_prime\n\n            logits_k = self._logits(h_k)\n            outputs.append(logits_k)\n            h_prev = h_k\n\n        # Стек logits: [B, seq_len, mtp_k, vocab_size]\n        return torch.stack(outputs, dim=2)","metadata":{"id":"uZPwLpubxYIb","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:24:43.791089Z","iopub.execute_input":"2025-12-15T18:24:43.791633Z","iopub.status.idle":"2025-12-15T18:24:43.801985Z","shell.execute_reply.started":"2025-12-15T18:24:43.791608Z","shell.execute_reply":"2025-12-15T18:24:43.801330Z"}},"outputs":[],"execution_count":7},{"id":"b3186b98","cell_type":"code","source":"x = torch.LongTensor(\n    [\n        [3, 1, 2, 0, 0],\n        [4, 1, 2, 0, 0],\n        [3, 1, 2, 0, 0],\n        [2, 1, 2, 4, 6],\n    ]\n)\n\ntransformer_mtp = MTPTransformer(\n    vocab_size=50,\n    n_layers=3,\n    embedding_size=64,\n    num_heads=8,\n    num_experts=16,\n    num_experts_per_token=8,\n    head_embedding_size=32,\n    fcnn_hidden_size=128,\n    dropout = 0.1,\n    mtp_k = 2\n)\n\nattention_mask = (x != 0).float()\n\noutput = transformer_mtp(x, attention_mask=attention_mask)\nprint(output.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3186b98","outputId":"892e4c0c-589a-4b96-a7c0-3120d1f1aca1","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:24:45.704473Z","iopub.execute_input":"2025-12-15T18:24:45.705182Z","iopub.status.idle":"2025-12-15T18:24:46.172568Z","shell.execute_reply.started":"2025-12-15T18:24:45.705152Z","shell.execute_reply":"2025-12-15T18:24:46.171813Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 2, 50])\n","output_type":"stream"}],"execution_count":8},{"id":"d9557664","cell_type":"markdown","source":"# TRAIN MODEL","metadata":{"id":"d9557664"}},{"id":"ZgtQWcYtsB9n","cell_type":"markdown","source":"#### Символьная языковая модель (character-level LM), которая обучена на корпусе имён и фамилий.\n\n**Вход**: начальный текст, например \"Красотка\" (может быть имя или часть фамилии).\n\n**Задача**: продолжить текст, сгенерировать следующие символы фамилии или имени, пока не встретится символ конца </s> или не будет достигнута максимальная длина.","metadata":{"id":"ZgtQWcYtsB9n"}},{"id":"7d2944cb","cell_type":"code","source":"class CharTokenizer:\n    def __init__(self):\n        self._start_token = \"<s>\"\n        self._end_token = \"</s>\"\n        self._unknown_token = \"<UNK>\"\n        self._padding_token = \"<PAD>\"\n        self._cls_token = \"<CLS>\"\n        self._sep_token = \"<SEP>\"\n        self._padding_id = 0\n        self._cls_id = 1\n        self._sep_id = 2\n        self._start_token_id = 3\n        self._end_token_id = 4\n        self._unknown_token_id = 5\n        self._init_vocab()\n\n    @property\n    def vocab(self) -> Mapping[int, str]:\n        return self._vocab\n\n    @property\n    def reverse_vocab(self) -> Mapping[int, str]:\n        return {token: id for id, token in self._vocab.items()}\n\n    @property\n    def start_token_id(self) -> int:\n        return self._start_token_id\n\n    @property\n    def end_token_id(self) -> int:\n        return self._end_token_id\n\n    def _init_vocab(self) -> None:\n        self._vocab = {\n            self._padding_id: self._padding_token,\n            self._cls_id: self._cls_token,\n            self._sep_id: self._sep_token,\n            self._start_token_id: self._start_token,\n            self._end_token_id: self._end_token,\n            self._unknown_token_id: self._unknown_token,\n        }\n\n    def fit(self, corpus: List[str]) -> Self:\n        self._init_vocab()\n        flat_corpus = \"\\n\".join(corpus)\n        for char in set(flat_corpus):\n            if char in self._vocab.values():\n                continue\n            self._vocab[len(self._vocab)] = char\n        return self\n\n    def tokenize_text(self, text: str | List[str]) -> List[str] | List[List[str]]:\n        if isinstance(text, str):\n            return self._tokenize_text(text)\n        assert isinstance(text, list), \"`text` should be str or List[str]\"\n        return [self._tokenize_text(chunk) for chunk in text]\n\n    def tokenize_ids(self, text: str | List[str]) -> List[int] | List[List[int]]:\n        if isinstance(text, str):\n            return self._tokenize_ids(text)\n        assert isinstance(text, list), \"`text` should be str or List[str]\"\n        return [self._tokenize_ids(chunk) for chunk in text]\n\n    def decode(self, tokens: List[int]) -> str:\n        content = []\n        for token in tokens:\n            if token in [self._padding_id, self._cls_id, self._sep_id, self._start_token_id, self._end_token_id, self._unknown_token_id]:\n                continue\n            content.append(\n                self._vocab.get(token, self._unknown_token)\n            )\n        return \"\".join(content)\n\n    def _tokenize_text(self, text: str) -> List[str]:\n        tokens = [self._start_token]\n        reverse_vocab = self.reverse_vocab\n        for char in list(text):\n            if char in reverse_vocab:\n               tokens.append(char)\n            else:\n                tokens.append(self._unknown_token)\n        tokens.append(self._end_token)\n        return tokens\n\n    def _tokenize_ids(self, text: str) -> List[int]:\n        tokens = self._tokenize_text(text)\n        reversed_vocab = self.reverse_vocab\n        tokens_ids = [reversed_vocab[token] for token in tokens]\n        return tokens_ids","metadata":{"id":"7d2944cb","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:24:50.484796Z","iopub.execute_input":"2025-12-15T18:24:50.485094Z","iopub.status.idle":"2025-12-15T18:24:50.496487Z","shell.execute_reply.started":"2025-12-15T18:24:50.485073Z","shell.execute_reply":"2025-12-15T18:24:50.495935Z"}},"outputs":[],"execution_count":9},{"id":"23d63ab4","cell_type":"code","source":"names = pl.read_parquet(\"names.parquet\")\nsurnames = pl.read_parquet(\"surnames.parquet\")\n\ndef get_persons(names: pl.DataFrame, surnames: pl.DataFrame, n: int = 100) -> List[str]:\n    persons = []\n    for _ in range(n):\n        sex = np.random.choice([\"m\", \"f\"]).item()\n        name = names.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n        surname = surnames.filter(pl.col(\"gender\") == sex).sample(1).select(\"text\").item()\n        persons.append(f\"{name} {surname}\")\n    return persons\n\ncorpus = get_persons(names, surnames, 10_000)\ncorpus[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23d63ab4","outputId":"c3b5be4d-7fc5-4975-d3d2-65f37cb7b22b","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:16.347321Z","iopub.execute_input":"2025-12-15T18:25:16.347585Z","iopub.status.idle":"2025-12-15T18:25:33.748604Z","shell.execute_reply.started":"2025-12-15T18:25:16.347565Z","shell.execute_reply":"2025-12-15T18:25:33.748023Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['Виталий Станченков',\n 'Анжела Комденкова',\n 'Марат Крапин',\n 'Виталий Порубов',\n 'Пётр Хацигов',\n 'Валериан Шульганов',\n 'Роза Девичева',\n 'Олег Бузеев',\n 'Василий Топинский',\n 'Рафаил Шабашов']"},"metadata":{}}],"execution_count":10},{"id":"6bc28635","cell_type":"code","source":"tokenizer = CharTokenizer().fit(corpus)","metadata":{"id":"6bc28635","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:37.605650Z","iopub.execute_input":"2025-12-15T18:25:37.606343Z","iopub.status.idle":"2025-12-15T18:25:37.619062Z","shell.execute_reply.started":"2025-12-15T18:25:37.606320Z","shell.execute_reply":"2025-12-15T18:25:37.618368Z"}},"outputs":[],"execution_count":11},{"id":"9262c9c0","cell_type":"code","source":"tokenizer.vocab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9262c9c0","outputId":"6904ef59-cfcc-4298-f596-44815f71d4de","jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:38.522087Z","iopub.execute_input":"2025-12-15T18:25:38.522692Z","iopub.status.idle":"2025-12-15T18:25:38.527580Z","shell.execute_reply.started":"2025-12-15T18:25:38.522657Z","shell.execute_reply":"2025-12-15T18:25:38.527074Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{0: '<PAD>',\n 1: '<CLS>',\n 2: '<SEP>',\n 3: '<s>',\n 4: '</s>',\n 5: '<UNK>',\n 6: 'б',\n 7: 'Д',\n 8: '\\n',\n 9: 'У',\n 10: 'к',\n 11: 'г',\n 12: 'х',\n 13: 'у',\n 14: 'Ч',\n 15: 'К',\n 16: 'ц',\n 17: 'В',\n 18: 'о',\n 19: 'П',\n 20: 'Щ',\n 21: 'л',\n 22: 'ь',\n 23: 'Н',\n 24: 'Э',\n 25: 'ш',\n 26: 'Л',\n 27: ' ',\n 28: 'е',\n 29: 'М',\n 30: 'Ш',\n 31: 'v',\n 32: 'й',\n 33: '-',\n 34: 'з',\n 35: 'Б',\n 36: 'Е',\n 37: 'щ',\n 38: 'И',\n 39: 'р',\n 40: '0',\n 41: 'э',\n 42: 'ё',\n 43: 'ъ',\n 44: 'h',\n 45: 'т',\n 46: 'Т',\n 47: 'м',\n 48: 'З',\n 49: 'Я',\n 50: ',',\n 51: 'Х',\n 52: 'п',\n 53: 'с',\n 54: 'а',\n 55: 'я',\n 56: 'Р',\n 57: 'ж',\n 58: 'Ю',\n 59: 'в',\n 60: 'Г',\n 61: 'C',\n 62: 'и',\n 63: 'Ф',\n 64: 'О',\n 65: 'ю',\n 66: 'А',\n 67: 'н',\n 68: 'С',\n 69: 'ы',\n 70: 'ф',\n 71: 'Ц',\n 72: 'д',\n 73: 'ч',\n 74: 'Ж',\n 75: 'p'}"},"metadata":{}}],"execution_count":12},{"id":"f8883ab5","cell_type":"code","source":"class SimpleTextDataset(Dataset):\n    def __init__(\n        self,\n        corpus: List[str],\n        fitted_tokenizer: CharTokenizer,\n        max_seq_length: int = 100,\n    ):\n        self._data: List[List[int]] = []\n\n        for sentence in corpus:\n            x = fitted_tokenizer.tokenize_ids(sentence[:max_seq_length - 2])\n            self._data.append(x)\n\n    def __len__(self) -> int:\n        return len(self._data)\n\n    def __getitem__(self, idx: int) -> Tuple[List[int], List[int]]:\n        return torch.LongTensor(self._data[idx])\n","metadata":{"id":"f8883ab5","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:46.368854Z","iopub.execute_input":"2025-12-15T18:25:46.369114Z","iopub.status.idle":"2025-12-15T18:25:46.374152Z","shell.execute_reply.started":"2025-12-15T18:25:46.369095Z","shell.execute_reply":"2025-12-15T18:25:46.373462Z"}},"outputs":[],"execution_count":13},{"id":"b740a5df","cell_type":"code","source":"def collate(data: List[torch.Tensor]):\n    x = [torch.LongTensor(seq) for seq in data]\n    return nn.utils.rnn.pad_sequence(x, batch_first=True)","metadata":{"id":"b740a5df","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:47.904473Z","iopub.execute_input":"2025-12-15T18:25:47.905180Z","iopub.status.idle":"2025-12-15T18:25:47.908654Z","shell.execute_reply.started":"2025-12-15T18:25:47.905155Z","shell.execute_reply":"2025-12-15T18:25:47.908092Z"}},"outputs":[],"execution_count":14},{"id":"083643c1","cell_type":"code","source":"VOCAB_SIZE = len(tokenizer.vocab)\nBATCH_SIZE = 256\nMAX_SEQ_LEN = 200\nN_LAYERS = 6\nEMBEDDING_SIZE = 64\nNUM_HEADS = 8\nNUM_KV_GROUPS = 2\nNUM_EXPERTS = 16\nNUM_EXPERTS_PER_TOKEN = 2\nHEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\nFCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\nMTP_K = 3\nn_epoch = 20","metadata":{"id":"083643c1","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:50.065598Z","iopub.execute_input":"2025-12-15T18:25:50.065886Z","iopub.status.idle":"2025-12-15T18:25:50.070068Z","shell.execute_reply.started":"2025-12-15T18:25:50.065866Z","shell.execute_reply":"2025-12-15T18:25:50.069387Z"}},"outputs":[],"execution_count":15},{"id":"5b689383","cell_type":"code","source":"dataset = SimpleTextDataset(\n    corpus=corpus,\n    fitted_tokenizer=tokenizer,\n    max_seq_length=MAX_SEQ_LEN,\n)\ndataloader = DataLoader(\n    dataset=dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=collate\n)","metadata":{"id":"5b689383","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:53.985798Z","iopub.execute_input":"2025-12-15T18:25:53.986325Z","iopub.status.idle":"2025-12-15T18:25:54.109058Z","shell.execute_reply.started":"2025-12-15T18:25:53.986303Z","shell.execute_reply":"2025-12-15T18:25:54.108556Z"}},"outputs":[],"execution_count":16},{"id":"38d11b09","cell_type":"code","source":"next(iter(dataloader)).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38d11b09","outputId":"a60bb068-cd6d-47cc-e207-27a7663089cf","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:55.542755Z","iopub.execute_input":"2025-12-15T18:25:55.543236Z","iopub.status.idle":"2025-12-15T18:25:55.556898Z","shell.execute_reply.started":"2025-12-15T18:25:55.543214Z","shell.execute_reply":"2025-12-15T18:25:55.556301Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"torch.Size([256, 25])"},"metadata":{}}],"execution_count":17},{"id":"2313eee5","cell_type":"code","source":"transformer_mtp = MTPTransformer(\n    vocab_size=VOCAB_SIZE,\n    n_layers=N_LAYERS,\n    embedding_size=EMBEDDING_SIZE,\n    num_heads=NUM_HEADS,\n    num_experts=NUM_EXPERTS,\n    num_experts_per_token=NUM_EXPERTS_PER_TOKEN,\n    head_embedding_size=HEAD_EMBEDDING_SIZE,\n    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n    dropout = 0.15,\n    mtp_k = MTP_K\n)\n\noptimizer = Adam(transformer_mtp.parameters(), lr=4e-3)\nloss_func = nn.CrossEntropyLoss(reduction='none')","metadata":{"id":"2313eee5","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:56.327432Z","iopub.execute_input":"2025-12-15T18:25:56.327829Z","iopub.status.idle":"2025-12-15T18:25:59.750375Z","shell.execute_reply.started":"2025-12-15T18:25:56.327808Z","shell.execute_reply":"2025-12-15T18:25:59.749825Z"}},"outputs":[],"execution_count":18},{"id":"4a5f7551","cell_type":"code","source":"import math\nimport torch\nimport torch.nn.functional as F\n\ndef compute_perplexity(model, dataloader, loss_func, device):\n    model.eval()\n    total_loss = 0.0\n    total_tokens = 0\n\n    with torch.no_grad():\n        for x in dataloader:\n            x = x.to(device)  # [B, T]\n            \n            # Создаем attention mask\n            attention_mask = (x != 0).float()  # [B, T]\n            \n            curr_x = x[:, :-1]        # [B, T-1] вход\n            next_x = x[:, 1:]         # [B, T-1] цели\n            \n            # Передаем маску в модель\n            logits = model(curr_x, attention_mask=attention_mask[:, :-1])  # [B, L, K, V]\n            B, L, K, V = logits.shape\n\n            # Только main head (k=0)\n            logits_main = logits[:, :, 0, :]      # [B, L, V]\n            targets = next_x[:, :L]               # [B, L]\n\n            # Маска для валидных токенов (не PAD и не EOS)\n            mask = (targets != 0) & (targets != 4)  # [B, L]\n\n            if mask.any():\n                logits_flat = logits_main[mask]     # [N, V]\n                targets_flat = targets[mask]        # [N]\n\n                ce = F.cross_entropy(\n                    logits_flat,\n                    targets_flat,\n                    reduction='sum'\n                )\n                total_loss += ce.item()\n                total_tokens += mask.sum().item()\n\n    if total_tokens == 0:\n        return float('inf')\n\n    mean_nll = total_loss / total_tokens\n    return math.exp(mean_nll)","metadata":{"id":"4a5f7551","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:25:59.751352Z","iopub.execute_input":"2025-12-15T18:25:59.751746Z","iopub.status.idle":"2025-12-15T18:25:59.757894Z","shell.execute_reply.started":"2025-12-15T18:25:59.751722Z","shell.execute_reply":"2025-12-15T18:25:59.757241Z"}},"outputs":[],"execution_count":19},{"id":"3d012cda-fad7-4c6c-a5d6-5019027e251b","cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\n\ndef train_and_collect(model, n_epoch, dataloader, loss_func, optimizer, num_experts, device, mtp_lambda=0.3):\n    epoch_loss = []\n    expert_usage_list = []\n    ppl_list = []\n\n    for epoch in range(n_epoch):\n        model.train()\n        losses = []\n        print(f\"Epoch {epoch+1}\")\n\n        all_layers_topk_indices = []\n\n        for x in tqdm(dataloader):\n            B, T = x.shape\n            K = model.mtp_k\n            V = model.vocab_size  # Размерность словаря (предположим, что ты знаешь V заранее)\n\n            # === НОВОЕ: Создаем attention mask ===\n            attention_mask = (x != 0).float().to(device)  # [B, T]\n\n            # Вход для модели\n            curr_x = x[:, :T-K].to(device)      # [B, T-K]\n            full_next_x = x[:, 1:T].to(device)  # [B, T-1]\n            \n            # === ПЕРЕДАЕМ МАСКУ В МОДЕЛЬ ===\n            logits = model(curr_x, attention_mask=attention_mask[:, :T-K], use_cache=False)\n            B_out, L, K_out, V = logits.shape\n\n            # ===== Main loss =====\n            main_logits = logits[:, :, 0, :].reshape(-1, V)\n            main_targets = full_next_x[:, :L].reshape(-1)\n\n            main_mask = main_targets != 0\n            main_loss_per_token = loss_func(main_logits, main_targets)\n            main_loss_per_token = main_loss_per_token[main_mask]\n\n            main_loss = (\n                main_loss_per_token.mean()\n                if main_loss_per_token.numel() > 0\n                else torch.tensor(0.0, device=device)\n            )\n\n            # ===== MTP loss =====\n            mtp_loss = 0.0\n\n            for k in range(1, K_out):\n                mtp_logits = logits[:, :, k, :].reshape(-1, V)\n                mtp_targets = full_next_x[:, k:k+L].reshape(-1)\n\n                mtp_mask = mtp_targets != 0\n                if mtp_mask.sum() == 0:\n                    continue\n\n                loss_per_token = loss_func(mtp_logits, mtp_targets)\n                mtp_loss += loss_per_token[mtp_mask].mean()\n\n            # Скалируем MTP loss по количеству слоев\n            mtp_loss = (mtp_loss / max(1, K_out - 1)) * mtp_lambda\n\n            # Общая потеря\n            total_loss = main_loss + mtp_loss\n            losses.append(total_loss.item())\n\n            # MoE usage (без изменений)\n            batch_indices = []\n            for layer in model.main_layers:\n                if hasattr(layer._fcnn, 'last_topk_indices') and layer._fcnn.last_topk_indices is not None:\n                    batch_indices.append(layer._fcnn.last_topk_indices.detach())\n            for block in model.mtp_layers:  # mtp_block - это MTPBlock\n                for layer in block:  # layer - это DecoderLayer\n                    if hasattr(layer._fcnn, 'last_topk_indices') and layer._fcnn.last_topk_indices is not None:\n                        batch_indices.append(layer._fcnn.last_topk_indices.detach())\n\n            if batch_indices:\n                combined_batch = torch.cat(batch_indices, dim=0)\n                all_layers_topk_indices.append(combined_batch)\n\n            # Backpropagation\n            optimizer.zero_grad()\n            total_loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        # Подсчет потерь по эпохам\n        epoch_loss.append(np.mean(losses))\n\n        # Подсчет использования экспертов\n        if all_layers_topk_indices:\n            all_topk_flat = torch.cat([t.reshape(-1) for t in all_layers_topk_indices])\n            usage = np.array([(all_topk_flat.cpu().numpy() == i).sum() for i in range(num_experts)])\n        else:\n            usage = np.zeros(num_experts, dtype=int)\n\n        expert_usage_list.append(usage)\n\n        # Подсчет PPL (перплексии)\n        ppl = compute_perplexity(model, dataloader, loss_func, device)\n        ppl_list.append(ppl)\n\n        # Печать результата по эпохам\n        print(f\"Loss: {epoch_loss[-1]:.4f} | PPL: {ppl:.4f}\")\n\n    return epoch_loss, expert_usage_list, ppl_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:36:46.783375Z","iopub.execute_input":"2025-12-15T18:36:46.784059Z","iopub.status.idle":"2025-12-15T18:36:46.795851Z","shell.execute_reply.started":"2025-12-15T18:36:46.784032Z","shell.execute_reply":"2025-12-15T18:36:46.795190Z"}},"outputs":[],"execution_count":26},{"id":"7a275895","cell_type":"code","source":"device = \"cuda\"\ntransformer_mtp.to(device)\n\nloss_mha, usage_mha, ppl_mha = train_and_collect(\n  transformer_mtp, 100, dataloader, loss_func, optimizer, NUM_EXPERTS, device\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7a275895","outputId":"a2c11e3a-57ab-44a9-de35-b51cdd292e8c","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T18:36:49.456782Z","iopub.execute_input":"2025-12-15T18:36:49.457329Z","iopub.status.idle":"2025-12-15T19:17:11.742341Z","shell.execute_reply.started":"2025-12-15T18:36:49.457303Z","shell.execute_reply":"2025-12-15T19:17:11.741741Z"}},"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:18<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 7.2362 | PPL: 9.7483\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 2.5217 | PPL: 5.7023\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 2.0849 | PPL: 4.8193\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.9405 | PPL: 4.4533\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8768 | PPL: 4.4442\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8460 | PPL: 4.2595\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.8064 | PPL: 4.2361\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7951 | PPL: 4.1650\nEpoch 9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7757 | PPL: 4.1355\nEpoch 10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7583 | PPL: 4.0455\nEpoch 11\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7390 | PPL: 4.0460\nEpoch 12\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7311 | PPL: 3.9675\nEpoch 13\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7292 | PPL: 3.9517\nEpoch 14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7154 | PPL: 3.9531\nEpoch 15\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7071 | PPL: 3.9285\nEpoch 16\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6918 | PPL: 3.9190\nEpoch 17\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6798 | PPL: 3.8430\nEpoch 18\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6800 | PPL: 3.7917\nEpoch 19\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6664 | PPL: 3.7820\nEpoch 20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6537 | PPL: 3.7503\nEpoch 21\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6429 | PPL: 3.7565\nEpoch 22\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6397 | PPL: 3.7176\nEpoch 23\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6338 | PPL: 3.6820\nEpoch 24\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6285 | PPL: 3.6589\nEpoch 25\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6206 | PPL: 3.6403\nEpoch 26\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6139 | PPL: 3.6555\nEpoch 27\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.6104 | PPL: 3.6186\nEpoch 28\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5942 | PPL: 3.5976\nEpoch 29\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5941 | PPL: 3.5534\nEpoch 30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5869 | PPL: 3.5259\nEpoch 31\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5732 | PPL: 3.4779\nEpoch 32\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5673 | PPL: 3.5180\nEpoch 33\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5626 | PPL: 3.4802\nEpoch 34\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5492 | PPL: 3.4455\nEpoch 35\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5446 | PPL: 3.4217\nEpoch 36\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5396 | PPL: 3.3638\nEpoch 37\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5346 | PPL: 3.3542\nEpoch 38\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5220 | PPL: 3.3609\nEpoch 39\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5198 | PPL: 3.2961\nEpoch 40\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5090 | PPL: 3.3095\nEpoch 41\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.5079 | PPL: 3.2905\nEpoch 42\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4955 | PPL: 3.2149\nEpoch 43\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4900 | PPL: 3.2118\nEpoch 44\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4766 | PPL: 3.1630\nEpoch 45\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4772 | PPL: 3.1529\nEpoch 46\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4657 | PPL: 3.1339\nEpoch 47\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4590 | PPL: 3.1339\nEpoch 48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4571 | PPL: 3.0885\nEpoch 49\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4420 | PPL: 3.0703\nEpoch 50\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4397 | PPL: 3.0430\nEpoch 51\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4329 | PPL: 3.0260\nEpoch 52\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4312 | PPL: 3.0294\nEpoch 53\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4137 | PPL: 2.9761\nEpoch 54\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4135 | PPL: 2.9491\nEpoch 55\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4051 | PPL: 2.9415\nEpoch 56\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3999 | PPL: 2.9091\nEpoch 57\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3949 | PPL: 2.9124\nEpoch 58\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3905 | PPL: 2.8887\nEpoch 59\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3820 | PPL: 2.8730\nEpoch 60\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3786 | PPL: 2.8386\nEpoch 61\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3697 | PPL: 2.8059\nEpoch 62\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3638 | PPL: 2.7991\nEpoch 63\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3501 | PPL: 2.7873\nEpoch 64\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3455 | PPL: 2.7665\nEpoch 65\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3393 | PPL: 2.7329\nEpoch 66\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3426 | PPL: 2.7173\nEpoch 67\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3237 | PPL: 2.7098\nEpoch 68\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3249 | PPL: 2.6948\nEpoch 69\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3189 | PPL: 2.6715\nEpoch 70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3113 | PPL: 2.6725\nEpoch 71\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3067 | PPL: 2.6311\nEpoch 72\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.3025 | PPL: 2.6194\nEpoch 73\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2931 | PPL: 2.6088\nEpoch 74\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2914 | PPL: 2.5702\nEpoch 75\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2777 | PPL: 2.5499\nEpoch 76\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2713 | PPL: 2.5567\nEpoch 77\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2690 | PPL: 2.5654\nEpoch 78\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2625 | PPL: 2.5184\nEpoch 79\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2643 | PPL: 2.5121\nEpoch 80\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2534 | PPL: 2.4801\nEpoch 81\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2480 | PPL: 2.4616\nEpoch 82\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2444 | PPL: 2.4534\nEpoch 83\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2381 | PPL: 2.4465\nEpoch 84\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2331 | PPL: 2.4232\nEpoch 85\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2305 | PPL: 2.4414\nEpoch 86\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2249 | PPL: 2.4130\nEpoch 87\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2179 | PPL: 2.4133\nEpoch 88\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2161 | PPL: 2.3838\nEpoch 89\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2102 | PPL: 2.3671\nEpoch 90\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2081 | PPL: 2.3842\nEpoch 91\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.2022 | PPL: 2.3628\nEpoch 92\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1983 | PPL: 2.3364\nEpoch 93\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1987 | PPL: 2.3513\nEpoch 94\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1923 | PPL: 2.3259\nEpoch 95\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1830 | PPL: 2.3073\nEpoch 96\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1771 | PPL: 2.3017\nEpoch 97\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1737 | PPL: 2.2888\nEpoch 98\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1739 | PPL: 2.2802\nEpoch 99\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:16<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1725 | PPL: 2.2650\nEpoch 100\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:17<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1679 | PPL: 2.2659\n","output_type":"stream"}],"execution_count":27},{"id":"_9vDkaImiBDG","cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = range(1, len(loss_mha)+1)\n\nfig, ax1 = plt.subplots(figsize=(8,5))\n\n# ===== Loss =====\nax1.plot(epochs, loss_mha, 'b-o', label='Loss MHA')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss', color='b')\nax1.tick_params(axis='y', labelcolor='b')\n\n# ===== PPL =====\nax2 = ax1.twinx()  # создаем вторую ось Y\nax2.plot(epochs, ppl_mha, 'r-o', label='PPL MHA')\nax2.set_ylabel('Perplexity', color='r')\nax2.tick_params(axis='y', labelcolor='r')\n\n# ===== легенда =====\nlines, labels = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines + lines2, labels + labels2, loc='upper right')\n\nplt.title(\"Loss & Perplexity Comparison\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"_9vDkaImiBDG","outputId":"6b57ce22-c13f-4d7c-e80b-9af50bfada33","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:17:18.350055Z","iopub.execute_input":"2025-12-15T19:17:18.350316Z","iopub.status.idle":"2025-12-15T19:17:18.749802Z","shell.execute_reply.started":"2025-12-15T19:17:18.350297Z","shell.execute_reply":"2025-12-15T19:17:18.749219Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":28},{"id":"f8821cf7","cell_type":"code","source":"def model_memory_size(model, input_dtype=torch.float32):\n    total_params = 0\n    total_grads = 0\n    for param in model.parameters():\n        # Calculate total number of elements per parameter\n        param_size = param.numel()\n        total_params += param_size\n        # Check if gradients are stored for this parameter\n        if param.requires_grad:\n            total_grads += param_size\n\n    # Calculate buffer size (non-parameters that require memory)\n    total_buffers = sum(buf.numel() for buf in model.buffers())\n\n    # Size in bytes = (Number of elements) * (Size of each element in bytes)\n    # We assume parameters and gradients are stored in the same type as input dtype\n    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n\n    # Convert bytes to megabytes\n    total_memory_mb = total_memory_bytes / (1024**2)\n\n    return total_memory_mb\n\nprint(f\"float32 (PyTorch default): {model_memory_size(transformer_mtp, input_dtype=torch.float32):.4f} MB\")\nprint(f\"bfloat16: {model_memory_size(transformer_mtp, input_dtype=torch.bfloat16):.4f} MB\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8821cf7","outputId":"f32588e5-f46a-4662-94ac-977504f2e6b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:17:22.642827Z","iopub.execute_input":"2025-12-15T19:17:22.643504Z","iopub.status.idle":"2025-12-15T19:17:22.657209Z","shell.execute_reply.started":"2025-12-15T19:17:22.643479Z","shell.execute_reply":"2025-12-15T19:17:22.656505Z"}},"outputs":[{"name":"stdout","text":"float32 (PyTorch default): 110.0181 MB\nbfloat16: 55.0090 MB\n","output_type":"stream"}],"execution_count":29},{"id":"059c0d5b","cell_type":"markdown","source":"# TEST MODEL","metadata":{"id":"059c0d5b"}},{"id":"9b6bfc0f-4a2a-4e4e-b6bb-2e7fddc9f211","cell_type":"code","source":"def generate(\n    model: nn.Module,\n    text_input: str,\n    tokenizer: CharTokenizer,\n    max_steps: int = 100,\n    device: str = \"cuda\",\n    temperature: float = 1.0,\n    top_k: int = 50\n) -> str:\n    model.eval()\n    model.to(device)\n\n    # Токенизируем вход\n    input_tokens = tokenizer.tokenize_ids(text_input)\n    x = torch.tensor([input_tokens], dtype=torch.long, device=device)  # [1, T]\n\n    generated_tokens = input_tokens.copy()\n\n    for step in range(max_steps):\n        with torch.no_grad():\n            # **КЛЮЧЕВОЕ: используем ТОЛЬКО main prediction k=0**\n            logits = model(x)  # [1, L, K, V]\n\n            # Берем logits с последней позиции, main head (k=0)\n            next_logits = logits[0, -1, 0] / temperature  # [V]\n\n            # Top-K sampling\n            if top_k > 0:\n                v, _ = torch.topk(next_logits, min(top_k, next_logits.size(-1)))\n                next_logits[torch.lt(next_logits, v[0])] = -float('Inf')\n\n            probs = F.softmax(next_logits, dim=-1)\n            next_token = torch.multinomial(probs, num_samples=1)\n\n        next_token_id = next_token.item()\n        generated_tokens.append(next_token_id)\n\n        # Останавливаемся на EOS\n        if next_token_id == 4:  # <EOS>\n            break\n\n        # Добавляем токен к последовательности\n        x = torch.cat([x, next_token.unsqueeze(0)], dim=1)\n\n    return tokenizer.decode(generated_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:17:26.290480Z","iopub.execute_input":"2025-12-15T19:17:26.291180Z","iopub.status.idle":"2025-12-15T19:17:26.298059Z","shell.execute_reply.started":"2025-12-15T19:17:26.291156Z","shell.execute_reply":"2025-12-15T19:17:26.297334Z"}},"outputs":[],"execution_count":30},{"id":"e8016cab","cell_type":"code","source":"transformer_mtp.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8016cab","outputId":"0ea3718b-9467-418c-9957-6f7b858d1dd7","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:17:29.013096Z","iopub.execute_input":"2025-12-15T19:17:29.013769Z","iopub.status.idle":"2025-12-15T19:17:29.024973Z","shell.execute_reply.started":"2025-12-15T19:17:29.013742Z","shell.execute_reply":"2025-12-15T19:17:29.024352Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"MTPTransformer(\n  (_embeddings): Embedding(76, 64, padding_idx=0)\n  (main_layers): ModuleList(\n    (0-5): 6 x DecoderLayer(\n      (_mla): MultiHeadLatentAttention(\n        (W_Q): Linear(in_features=64, out_features=64, bias=False)\n        (W_C): Linear(in_features=64, out_features=16, bias=False)\n        (W_K): Linear(in_features=16, out_features=64, bias=False)\n        (W_V): Linear(in_features=16, out_features=64, bias=False)\n        (W_O): Linear(in_features=64, out_features=64, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (_fcnn): MoENoisyTopKGateFeedForward(\n        (_gate): Linear(in_features=64, out_features=16, bias=False)\n        (_noise_linear): Linear(in_features=64, out_features=16, bias=False)\n        (_fc1): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc2): ModuleList(\n          (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n        )\n        (_fc3): ModuleList(\n          (0-15): 16 x Linear(in_features=256, out_features=64, bias=False)\n        )\n      )\n      (_rms_norm1): RMSNorm()\n      (_rms_norm2): RMSNorm()\n      (_dropout): Dropout(p=0.15, inplace=False)\n    )\n  )\n  (mtp_layers): ModuleList(\n    (0-1): 2 x ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (_mla): MultiHeadLatentAttention(\n          (W_Q): Linear(in_features=64, out_features=64, bias=False)\n          (W_C): Linear(in_features=64, out_features=16, bias=False)\n          (W_K): Linear(in_features=16, out_features=64, bias=False)\n          (W_V): Linear(in_features=16, out_features=64, bias=False)\n          (W_O): Linear(in_features=64, out_features=64, bias=True)\n          (dropout): Dropout(p=0.15, inplace=False)\n        )\n        (_fcnn): MoENoisyTopKGateFeedForward(\n          (_gate): Linear(in_features=64, out_features=16, bias=False)\n          (_noise_linear): Linear(in_features=64, out_features=16, bias=False)\n          (_fc1): ModuleList(\n            (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n          )\n          (_fc2): ModuleList(\n            (0-15): 16 x Linear(in_features=64, out_features=256, bias=False)\n          )\n          (_fc3): ModuleList(\n            (0-15): 16 x Linear(in_features=256, out_features=64, bias=False)\n          )\n        )\n        (_rms_norm1): RMSNorm()\n        (_rms_norm2): RMSNorm()\n        (_dropout): Dropout(p=0.15, inplace=False)\n      )\n    )\n  )\n  (_rms_norm): RMSNorm()\n  (projections): ModuleList(\n    (0-1): 2 x Linear(in_features=128, out_features=64, bias=True)\n  )\n  (_logits): Linear(in_features=64, out_features=76, bias=False)\n)"},"metadata":{}}],"execution_count":31},{"id":"f4a4c3f8","cell_type":"code","source":"generate(\n    model=transformer_mtp,\n    text_input=\"Красота\",\n    tokenizer=tokenizer,\n    device=device,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f4a4c3f8","outputId":"bc9dc6e3-ae36-410f-8cc6-fe2670e664ed","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:18:11.698745Z","iopub.execute_input":"2025-12-15T19:18:11.699242Z","iopub.status.idle":"2025-12-15T19:18:13.647848Z","shell.execute_reply.started":"2025-12-15T19:18:11.699217Z","shell.execute_reply":"2025-12-15T19:18:13.647218Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'Красотаваниь тняСрукеисовноваава'"},"metadata":{}}],"execution_count":36},{"id":"1f80b1e3-0c21-437b-84c6-47f2351f2416","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}